{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pejmanrasti/EPU_ML_Angers_2023/blob/main/Jour_3/1_CycleGan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7eab9014",
      "metadata": {
        "id": "7eab9014"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96109220",
      "metadata": {
        "id": "96109220",
        "outputId": "5fbfdf72-d640-4fc6-d76d-a915a6089276"
      },
      "source": [
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fab8c7e0",
      "metadata": {
        "id": "fab8c7e0"
      },
      "outputs": [],
      "source": [
        "# example of training a cyclegan on the CT2MRI dataset\n",
        "from random import random\n",
        "from numpy import load\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy import asarray\n",
        "from numpy.random import randint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "#from tensorflow.python.keras.models import Input\n",
        "from tensorflow.keras.layers import Conv2D, Input\n",
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
        "from matplotlib import pyplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20b1ca77",
      "metadata": {
        "id": "20b1ca77"
      },
      "outputs": [],
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b25d6051",
      "metadata": {
        "id": "b25d6051"
      },
      "outputs": [],
      "source": [
        "# example of preparing the CT and MRI dataset\n",
        "from os import listdir\n",
        "from numpy import asarray\n",
        "from numpy import vstack\n",
        "from numpy import savez_compressed\n",
        "import tifffile as tiff\n",
        "from skimage.transform import resize\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "\n",
        "dim = (256, 256)\n",
        "# dataset path\n",
        "path = 'data/'\n",
        "# load dataset A\n",
        "dataA = tiff.imread(path + 'MR2.tif')\n",
        "dataA = cv2.resize(dataA, dim, interpolation=cv2.INTER_LINEAR)\n",
        "#dataA=resize(dataA,dim)\n",
        "dataA = np.array(dataA).reshape(-1, 256, 256)\n",
        "print('Loaded dataA: ', dataA.shape)\n",
        "# load dataset B\n",
        "dataB = tiff.imread(path + 'CT2.tif')\n",
        "dataB = cv2.resize(dataB, dim, interpolation=cv2.INTER_LINEAR)\n",
        "#dataB=resize(dataB,dim)\n",
        "dataB = np.array(dataB).reshape(-1, 256,256)\n",
        "print('Loaded dataB: ', dataB.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c4f0eb2",
      "metadata": {
        "id": "1c4f0eb2"
      },
      "outputs": [],
      "source": [
        "# save as compressed numpy array\n",
        "filename = 'data_patho.npz'\n",
        "savez_compressed(filename, dataA, dataB)\n",
        "print('Saved dataset: ', filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe3d66e8",
      "metadata": {
        "id": "fe3d66e8"
      },
      "outputs": [],
      "source": [
        "\n",
        "# load and plot the prepared dataset\n",
        "from numpy import load\n",
        "from matplotlib import pyplot\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# load the dataset\n",
        "data = load('data_patho.npz')\n",
        "dataA, dataB = data['arr_0'], data['arr_1']\n",
        "print('Loaded: ', dataA.shape, dataB.shape)\n",
        "dataA, dataB = shuffle(dataA, dataB, random_state=2)\n",
        "# plot source images\n",
        "n_samples = 1\n",
        "pyplot.figure(figsize=(10,10))\n",
        "for i in range(n_samples):\n",
        "\n",
        "    pyplot.subplot(2, n_samples, 1 + i)\n",
        "    pyplot.axis('off')\n",
        "    pyplot.imshow(dataA[i].astype('uint8'),cmap='gray')\n",
        "# plot target image\n",
        "pyplot.figure(figsize=(10,10))\n",
        "for i in range(n_samples):\n",
        "\n",
        "    pyplot.subplot(2, n_samples, 1 + n_samples + i)\n",
        "    pyplot.axis('off')\n",
        "    pyplot.imshow(dataB[i].astype('uint8'),cmap='gray')\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d69dfcd",
      "metadata": {
        "id": "9d69dfcd"
      },
      "outputs": [],
      "source": [
        "\n",
        "...\n",
        "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
        "# define layer\n",
        "layer = InstanceNormalization(axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2819cba",
      "metadata": {
        "id": "b2819cba"
      },
      "outputs": [],
      "source": [
        "\n",
        "# define the discriminator model\n",
        "def define_discriminator(image_shape):\n",
        "\t# weight initialization\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\t# source image input\n",
        "\tin_image = Input(shape=image_shape)\n",
        "\t# C64\n",
        "\td = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(in_image)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t# C128\n",
        "\td = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "\td = InstanceNormalization(axis=-1)(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t# C256\n",
        "\td = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "\td = InstanceNormalization(axis=-1)(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t# C512\n",
        "\td = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "\td = InstanceNormalization(axis=-1)(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t# second last output layer\n",
        "\td = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "\td = InstanceNormalization(axis=-1)(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t# patch output\n",
        "\tpatch_out = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n",
        "\t# define model\n",
        "\tmodel = Model(in_image, patch_out)\n",
        "\t# compile model\n",
        "\tmodel.compile(loss='mse', optimizer=Adam(lr=0.0002, beta_1=0.5), loss_weights=[0.5])\n",
        "\treturn model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91a9498e",
      "metadata": {
        "id": "91a9498e"
      },
      "outputs": [],
      "source": [
        "\n",
        "# generator a resnet block\n",
        "def resnet_block(n_filters, input_layer):\n",
        "\t# weight initialization\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\t# first layer convolutional layer\n",
        "\tg = Conv2D(n_filters, (3,3), padding='same', kernel_initializer=init)(input_layer)\n",
        "\tg = InstanceNormalization(axis=-1)(g)\n",
        "\tg = Activation('relu')(g)\n",
        "\t# second convolutional layer\n",
        "\tg = Conv2D(n_filters, (3,3), padding='same', kernel_initializer=init)(g)\n",
        "\tg = InstanceNormalization(axis=-1)(g)\n",
        "\t# concatenate merge channel-wise with input layer\n",
        "\tg = Concatenate()([g, input_layer])\n",
        "\treturn g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28076cae",
      "metadata": {
        "id": "28076cae"
      },
      "outputs": [],
      "source": [
        "def define_generator(image_shape, n_resnet=9):\n",
        "\t# weight initialization\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\t# image input\n",
        "\tin_image = Input(shape=image_shape)\n",
        "\t# c7s1-64\n",
        "\tg = Conv2D(64, (7,7), padding='same', kernel_initializer=init)(in_image)\n",
        "\tg = InstanceNormalization(axis=-1)(g)\n",
        "\tg = Activation('relu')(g)\n",
        "\t# d128\n",
        "\tg = Conv2D(64, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
        "\tg = InstanceNormalization(axis=-1)(g)\n",
        "\tg = Activation('relu')(g)\n",
        "\t# d256\n",
        "\tg = Conv2D(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
        "\tg = InstanceNormalization(axis=-1)(g)\n",
        "\tg = Activation('relu')(g)\n",
        "\t# R256\n",
        "\tfor _ in range(n_resnet):\n",
        "\t\tg = resnet_block(256, g)\n",
        "\t# u128\n",
        "\tg = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
        "\tg = InstanceNormalization(axis=-1)(g)\n",
        "\tg = Activation('relu')(g)\n",
        "\t# u64\n",
        "\tg = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
        "\tg = InstanceNormalization(axis=-1)(g)\n",
        "\tg = Activation('relu')(g)\n",
        "\t# c7s1-3\n",
        "\tg = Conv2D(1, (7,7), padding='same', kernel_initializer=init)(g)\n",
        "\tg = InstanceNormalization(axis=-1)(g)\n",
        "\tout_image = Activation('tanh')(g)\n",
        "\t# define model\n",
        "\tmodel = Model(in_image, out_image)\n",
        "\treturn model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b34ffda3",
      "metadata": {
        "id": "b34ffda3"
      },
      "outputs": [],
      "source": [
        "\n",
        "# define a composite model for updating generators by adversarial and cycle loss\n",
        "def define_composite_model(g_model_1, d_model, g_model_2, image_shape):\n",
        "\t# ensure the model we're updating is trainable\n",
        "\tg_model_1.trainable = True\n",
        "\t# mark discriminator as not trainable\n",
        "\td_model.trainable = False\n",
        "\t# mark other generator model as not trainable\n",
        "\tg_model_2.trainable = False\n",
        "\t# discriminator element\n",
        "\tinput_gen = Input(shape=image_shape)\n",
        "\tgen1_out = g_model_1(input_gen)\n",
        "\toutput_d = d_model(gen1_out)\n",
        "\t# identity element\n",
        "\tinput_id = Input(shape=image_shape)\n",
        "\toutput_id = g_model_1(input_id)\n",
        "\t# forward cycle\n",
        "\toutput_f = g_model_2(gen1_out)\n",
        "\t# backward cycle\n",
        "\tgen2_out = g_model_2(input_id)\n",
        "\toutput_b = g_model_1(gen2_out)\n",
        "\t# define model graph\n",
        "\tmodel = Model([input_gen, input_id], [output_d, output_id, output_f, output_b])\n",
        "\t# define optimization algorithm configuration\n",
        "\topt = Adam(lr=0.0004, beta_1=0.5)\n",
        "\t# compile model with weighting of least squares loss and L1 loss\n",
        "\tmodel.compile(loss=['mse', 'mae', 'mae', 'mae'], loss_weights=[1, 5, 5, 5], optimizer=opt)\n",
        "\treturn model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b84ed565",
      "metadata": {
        "id": "b84ed565"
      },
      "outputs": [],
      "source": [
        "# load and prepare training images\n",
        "def load_real_samples(filename):\n",
        "   # load the dataset\n",
        "    data = load(filename)\n",
        "    # unpack arrays\n",
        "    X1, X2 = data['arr_0'], data['arr_1']\n",
        "    X1=X1[:,:,:,None]\n",
        "    X2=X2[:,:,:,None]\n",
        "    # scale from [0,255] to [-1,1]\n",
        "    X1 = (X1 - 127.5) / 127.5\n",
        "    X2 = (X2 - 127.5) / 127.5\n",
        "    return [X1, X2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87c3205e",
      "metadata": {
        "id": "87c3205e"
      },
      "outputs": [],
      "source": [
        "# select a batch of random samples, returns images and target\n",
        "def generate_real_samples(dataset, n_samples, patch_shape):\n",
        "\t# choose random instances\n",
        "\tix = randint(0, dataset.shape[0], n_samples)\n",
        "\t# retrieve selected images\n",
        "\tX = dataset[ix]\n",
        "\t# generate 'real' class labels (1)\n",
        "\ty = ones((n_samples, patch_shape, patch_shape, 1))\n",
        "\treturn X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0507db11",
      "metadata": {
        "id": "0507db11"
      },
      "outputs": [],
      "source": [
        "# generate a batch of images, returns images and targets\n",
        "def generate_fake_samples(g_model, dataset, patch_shape):\n",
        "\t# generate fake instance\n",
        "\tX = g_model.predict(dataset)\n",
        "\t# create 'fake' class labels (0)\n",
        "\ty = zeros((len(X), patch_shape, patch_shape, 1))\n",
        "\treturn X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a225c94",
      "metadata": {
        "id": "5a225c94"
      },
      "outputs": [],
      "source": [
        "# save the generator models to file\n",
        "def save_models(step, g_model_AtoB, g_model_BtoA):\n",
        "\t# save the first generator model\n",
        "\tfilename1 = 'models/g_model_AtoB_%06d.h5' % (step+1)\n",
        "\tg_model_AtoB.save(filename1)\n",
        "\t# save the second generator model\n",
        "\tfilename2 = 'models/g_model_BtoA_%06d.h5' % (step+1)\n",
        "\tg_model_BtoA.save(filename2)\n",
        "\tprint('>Saved: %s and %s' % (filename1, filename2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b559faa2",
      "metadata": {
        "id": "b559faa2"
      },
      "outputs": [],
      "source": [
        "def summarize_performance(step, g_model, trainX, name, n_samples=5):\n",
        "\t# select a sample of input images\n",
        "\tX_in, _ = generate_real_samples(trainX, n_samples, 0)\n",
        "\t# generate translated images\n",
        "\tX_out, _ = generate_fake_samples(g_model, X_in, 0)\n",
        "\t# scale all pixels from [-1,1] to [0,1]\n",
        "\tX_in = (X_in + 1) / 2.0\n",
        "\tX_out = (X_out + 1) / 2.0\n",
        "\t# plot real images\n",
        "\tpyplot.figure(figsize=(20,20))\n",
        "\tfor i in range(n_samples):\n",
        "\t\tpyplot.subplot(2, n_samples, 1 + i)\n",
        "\t\tpyplot.axis('off')\n",
        "\t\tpyplot.imshow(X_in[i])\n",
        "\t# plot translated image\n",
        "\tfor i in range(n_samples):\n",
        "\t\tpyplot.subplot(2, n_samples, 1 + n_samples + i)\n",
        "\t\tpyplot.axis('off')\n",
        "\t\tpyplot.imshow(X_out[i])\n",
        "\t# save plot to file\n",
        "\tfilename1 = 'images_AB_BA/%s_generated_plot_%06d.png' % (name, (step+1))\n",
        "\tpyplot.savefig(filename1)\n",
        "\tpyplot.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c6f55e2",
      "metadata": {
        "id": "6c6f55e2"
      },
      "outputs": [],
      "source": [
        "\n",
        "# update image pool for fake images\n",
        "def update_image_pool(pool, images, max_size=50):\n",
        "\tselected = list()\n",
        "\tfor image in images:\n",
        "\t\tif len(pool) < max_size:\n",
        "\t\t\t# stock the pool\n",
        "\t\t\tpool.append(image)\n",
        "\t\t\tselected.append(image)\n",
        "\t\telif random() < 0.5:\n",
        "\t\t\t# use image, but don't add it to the pool\n",
        "\t\t\tselected.append(image)\n",
        "\t\telse:\n",
        "\t\t\t# replace an existing image and use replaced image\n",
        "\t\t\tix = randint(0, len(pool))\n",
        "\t\t\tselected.append(pool[ix])\n",
        "\t\t\tpool[ix] = image\n",
        "\treturn asarray(selected)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "379e3948",
      "metadata": {
        "id": "379e3948"
      },
      "outputs": [],
      "source": [
        "def train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, dataset):\n",
        "\t# define properties of the training run\n",
        "\tn_epochs, n_batch, = 40000, 1\n",
        "\t# determine the output square shape of the discriminator\n",
        "\tn_patch = d_model_A.output_shape[1]\n",
        "\t# unpack dataset\n",
        "\ttrainA, trainB = dataset\n",
        "\tprint(len(trainA))\n",
        "\t# prepare image pool for fakes\n",
        "\tpoolA, poolB = list(), list()\n",
        "\t# calculate the number of batches per training epoch\n",
        "\tbat_per_epo = int(len(trainA) / n_batch)\n",
        "\t# calculate the number of training iterations\n",
        "\tn_steps = bat_per_epo * n_epochs\n",
        "\tprint(n_steps)\n",
        "\t# manually enumerate epochs\n",
        "\tfor i in range(n_steps):\n",
        "\t\t# select a batch of real samples\n",
        "\t\tX_realA, y_realA = generate_real_samples(trainA, n_batch, n_patch)\n",
        "\t\tX_realB, y_realB = generate_real_samples(trainB, n_batch, n_patch)\n",
        "\t\t# generate a batch of fake samples\n",
        "\t\tX_fakeA, y_fakeA = generate_fake_samples(g_model_BtoA, X_realB, n_patch)\n",
        "\t\tX_fakeB, y_fakeB = generate_fake_samples(g_model_AtoB, X_realA, n_patch)\n",
        "\t\t# update fakes from pool\n",
        "\t\tX_fakeA = update_image_pool(poolA, X_fakeA)\n",
        "\t\tX_fakeB = update_image_pool(poolB, X_fakeB)\n",
        "\t\t# update generator B->A via adversarial and cycle loss\n",
        "\t\tg_loss2, _, _, _, _  = c_model_BtoA.train_on_batch([X_realB, X_realA], [y_realA, X_realA, X_realB, X_realA])\n",
        "\t\t# update discriminator for A -> [real/fake]\n",
        "\t\tdA_loss1 = d_model_A.train_on_batch(X_realA, y_realA)\n",
        "\t\tdA_loss2 = d_model_A.train_on_batch(X_fakeA, y_fakeA)\n",
        "\t\t# update generator A->B via adversarial and cycle loss\n",
        "\t\tg_loss1, _, _, _, _ = c_model_AtoB.train_on_batch([X_realA, X_realB], [y_realB, X_realB, X_realA, X_realB])\n",
        "\t\t# update discriminator for B -> [real/fake]\n",
        "\t\tdB_loss1 = d_model_B.train_on_batch(X_realB, y_realB)\n",
        "\t\tdB_loss2 = d_model_B.train_on_batch(X_fakeB, y_fakeB)\n",
        "\t\t# summarize performance\n",
        "\t\tprint('>%d, dA[%.3f,%.3f] dB[%.3f,%.3f] g[%.3f,%.3f]' % (i+1, dA_loss1,dA_loss2, dB_loss1,dB_loss2, g_loss1,g_loss2))\n",
        "\t\t# evaluate the model performance every so often\n",
        "\t\tif (i+1) % (bat_per_epo * 5) == 0:\n",
        "\t\t\t# plot A->B translation\n",
        "\t\t\tsummarize_performance(i, g_model_AtoB, trainA, 'AtoB')\n",
        "\t\t\t# plot B->A translation\n",
        "\t\t\tsummarize_performance(i, g_model_BtoA, trainB, 'BtoA')\n",
        "\t\tif (i+1) % (bat_per_epo * 10) == 0:\n",
        "\t\t\t# save the models\n",
        "\t\t\tsave_models(i, g_model_AtoB, g_model_BtoA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42c530ec",
      "metadata": {
        "id": "42c530ec"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.framework.ops import disable_eager_execution\n",
        "disable_eager_execution()\n",
        "# load image data\n",
        "dataset = load_real_samples('data_patho.npz')\n",
        "print('Loaded', dataset[0].shape, dataset[1].shape)\n",
        "# define input shape based on the loaded dataset\n",
        "image_shape = dataset[0].shape[1:]\n",
        "# generator: A -> B\n",
        "g_model_AtoB = define_generator(image_shape)\n",
        "print('done1')\n",
        "# generator: B -> A\n",
        "g_model_BtoA = define_generator(image_shape)\n",
        "print('done2')\n",
        "# discriminator: A -> [real/fake]\n",
        "d_model_A = define_discriminator(image_shape)\n",
        "# discriminator: B -> [real/fake]\n",
        "d_model_B = define_discriminator(image_shape)\n",
        "# composite: A -> B -> [real/fake, A]\n",
        "c_model_AtoB = define_composite_model(g_model_AtoB, d_model_B, g_model_BtoA, image_shape)\n",
        "# composite: B -> A -> [real/fake, B]\n",
        "c_model_BtoA = define_composite_model(g_model_BtoA, d_model_A, g_model_AtoB, image_shape)\n",
        "print('done2')\n",
        "# train models\n",
        "train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, dataset)\n",
        "print('done')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d88cdb49",
      "metadata": {
        "id": "d88cdb49"
      },
      "source": [
        "## perform style transfer with the saved models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac714a7a",
      "metadata": {
        "id": "ac714a7a",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "\n",
        "# example of using saved cyclegan models for image translation\n",
        "from keras.models import load_model\n",
        "from numpy import load\n",
        "from numpy import vstack\n",
        "from matplotlib import pyplot\n",
        "from numpy.random import randint\n",
        "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
        "# load and prepare training images\n",
        "from tensorflow.python.framework.ops import disable_eager_execution\n",
        "disable_eager_execution()\n",
        "def load_real_samples(filename):\n",
        "\t# load the dataset\n",
        "\tdata = load(filename)\n",
        "\t# unpack arrays\n",
        "\tX1, X2 = data['arr_0'], data['arr_1']\n",
        "\tX1=X1[:,:,:,None]\n",
        "\tX2=X2[:,:,:,None]\n",
        "\t# scale from [0,255] to [-1,1]\n",
        "\tX1 = (X1 - 127.5) / 127.5\n",
        "\tX2 = (X2 - 127.5) / 127.5\n",
        "\treturn [X1, X2]\n",
        "\n",
        "# select a random sample of images from the dataset\n",
        "def select_sample(dataset, n_samples):\n",
        "\t# choose random instances\n",
        "\tix = randint(0, dataset.shape[0], n_samples)\n",
        "\t# retrieve selected images\n",
        "\tX = dataset[ix]\n",
        "\treturn X\n",
        "\n",
        "# plot the image, the translation, and the reconstruction\n",
        "def show_plot(imagesX, imagesY1, imagesY2):\n",
        "\timages = vstack((imagesX, imagesY1, imagesY2))\n",
        "\ttitles = ['Real', 'Generated', 'Reconstructed']\n",
        "\t# scale from [-1,1] to [0,1]\n",
        "\timages = (images + 1) / 2.0\n",
        "\t# plot images row by row\n",
        "\tpyplot.figure(figsize=(20,20))\n",
        "\tfor i in range(len(images)):\n",
        "\t\t# define subplot\n",
        "\t\tpyplot.subplot(1, len(images), 1 + i)\n",
        "\t\t# turn off axis\n",
        "\t\tpyplot.axis('off')\n",
        "\t\t# plot raw pixel data\n",
        "\t\tpyplot.imshow(images[i], cmap='gray')\n",
        "\t\t# title\n",
        "\t\tpyplot.title(titles[i])\n",
        "\tpyplot.show()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "339f714b",
      "metadata": {
        "id": "339f714b"
      },
      "outputs": [],
      "source": [
        "\n",
        "dim = (256, 256)\n",
        "# dataset path\n",
        "path = 'data/'\n",
        "# load dataset A\n",
        "dataA = tiff.imread(path + 'MR1.tif')\n",
        "dataA = cv2.resize(dataA, dim, interpolation=cv2.INTER_LINEAR)\n",
        "#dataA=resize(dataA,dim)\n",
        "dataA = np.array(dataA).reshape(-1, 256, 256)\n",
        "print('Loaded dataA: ', dataA.shape)\n",
        "# load dataset B\n",
        "dataB = tiff.imread(path + 'CT1.tif')\n",
        "dataB = cv2.resize(dataB, dim, interpolation=cv2.INTER_LINEAR)\n",
        "#dataB=resize(dataB,dim)\n",
        "dataB = np.array(dataB).reshape(-1, 256,256)\n",
        "print('Loaded dataB: ', dataB.shape)\n",
        "# save as compressed numpy array\n",
        "filename = 'data_CTMRI1.npz'\n",
        "savez_compressed(filename, dataA, dataB)\n",
        "print('Saved dataset: ', filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02997b48",
      "metadata": {
        "id": "02997b48"
      },
      "outputs": [],
      "source": [
        "# load dataset\n",
        "A_data, B_data = load_real_samples('data_CTMRI1.npz')\n",
        "print('Loaded', A_data.shape, B_data.shape)\n",
        "# load the models\n",
        "cust = {'InstanceNormalization': InstanceNormalization}\n",
        "model_AtoB = load_model('models/g_model_AtoB_018100.h5', cust)\n",
        "model_BtoA = load_model('models/g_model_BtoA_018100.h5', cust)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dadd8c9",
      "metadata": {
        "id": "1dadd8c9",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# plot A->B->A\n",
        "A_real = select_sample(A_data, 1)\n",
        "B_generated  = model_AtoB.predict(A_real)\n",
        "A_reconstructed = model_BtoA.predict(B_generated)\n",
        "show_plot(A_real, B_generated, A_reconstructed)\n",
        "# plot B->A->B\n",
        "B_real = select_sample(B_data, 1)\n",
        "A_generated  = model_BtoA.predict(B_real)\n",
        "B_reconstructed = model_AtoB.predict(A_generated)\n",
        "show_plot(B_real, A_generated, B_reconstructed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2c483a4",
      "metadata": {
        "id": "a2c483a4"
      },
      "outputs": [],
      "source": [
        "# plot the image, the translation, and the reconstruction\n",
        "def show_plot_final(imagesX, imagesY1):\n",
        "\timages = vstack((imagesX, imagesY1))\n",
        "\ttitles = ['Real', 'Transfered']\n",
        "\t# scale from [-1,1] to [0,1]\n",
        "\timages = (images + 1) / 2.0\n",
        "\t# plot images row by row\n",
        "\tpyplot.figure(figsize=(20,20))\n",
        "\tfor i in range(len(images)):\n",
        "\t\t# define subplot\n",
        "\t\tpyplot.subplot(1, len(images), 1 + i)\n",
        "\t\t# turn off axis\n",
        "\t\tpyplot.axis('off')\n",
        "\t\t# plot raw pixel data\n",
        "\t\tpyplot.imshow(images[i], cmap='gray')\n",
        "\t\t# title\n",
        "\t\tpyplot.title(titles[i])\n",
        "\tpyplot.show()\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c7eca80",
      "metadata": {
        "id": "1c7eca80",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "B_real = select_sample(B_data, 1)\n",
        "B_denoised = model_BtoA.predict(B_real)\n",
        "show_plot_final(B_real, B_denoised)\n",
        "B_denoised = (B_denoised + 1) / 2.0\n",
        "tiff.imsave('CT2MR.tiff', B_denoised)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7634f091",
      "metadata": {
        "id": "7634f091"
      },
      "outputs": [],
      "source": [
        "A_real = select_sample(A_data, 1)\n",
        "A_denoised = model_AtoB.predict(A_real)\n",
        "show_plot_final(A_real, A_denoised)\n",
        "B_denoised = (A_denoised + 1) / 2.0\n",
        "tiff.imsave('MR2CT.tiff', B_denoised)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23cc639c",
      "metadata": {
        "id": "23cc639c"
      },
      "outputs": [],
      "source": [
        "dataC = tiff.imread(path + 'CT2.tif')\n",
        "dataC = cv2.resize(dataC, dim, interpolation=cv2.INTER_LINEAR)\n",
        "#dataB=resize(dataB,dim)\n",
        "dataC = np.array(dataC).reshape(-1, 256,256,1)\n",
        "\n",
        "C_denoised = model_BtoA.predict(dataC)\n",
        "show_plot_final(dataC, C_denoised)\n",
        "\n",
        "C_denoised = (C_denoised + 1) / 2.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "daeb9269",
      "metadata": {
        "id": "daeb9269"
      },
      "outputs": [],
      "source": [
        "C_denoised.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2b39fe9",
      "metadata": {
        "id": "d2b39fe9"
      },
      "outputs": [],
      "source": [
        "tiff.imsave('transfered.png', C_denoised)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dcc0eef",
      "metadata": {
        "id": "6dcc0eef"
      },
      "outputs": [],
      "source": [
        "dataD = tiff.imread(path + 'CT1.tif')\n",
        "dataD = cv2.resize(dataD, dim, interpolation=cv2.INTER_LINEAR)\n",
        "#dataB=resize(dataB,dim)\n",
        "dataD = np.array(dataD).reshape(-1, 256,256,1)\n",
        "\n",
        "D_denoised = model_BtoA.predict(dataD)\n",
        "show_plot_final(dataD, D_denoised)\n",
        "\n",
        "D_denoised = (D_denoised + 1) / 2.0\n",
        "tiff.imsave('CT1_2_MRI2.tiff', D_denoised)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b51e4164",
      "metadata": {
        "id": "b51e4164"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}