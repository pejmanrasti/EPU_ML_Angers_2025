{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8da40149-a5bb-44eb-8ee2-31b63088ec70",
   "metadata": {},
   "source": [
    "<font size = 8> ‚ö†Ô∏è</font>\n",
    "\n",
    "#  ERREURS COURANTES \n",
    "üîó [Documentation Scikit - Erreurs courantes](https://scikit-learn.org/stable/common_pitfalls.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbe9482-1f36-42fe-9aad-52da3aa90437",
   "metadata": {},
   "source": [
    "##  1. Pr√©-traitement des donn√©es incoh√©rent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed62dda-0f78-40a8-9e97-1e0088435866",
   "metadata": {},
   "source": [
    "Les transformations appliqu√©es aux variables d'entrainement doivent √©galement l'√™tre aux variables test et aux donn√©es nouvelles √† pr√©dire. Sinon le type des donn√©es d'entr√©e sera diff√©rent des donn√©es sur lesquelles le mod√®le s'est entrain√© (ordre de grandeur, distribution, etc) et donc il ne sera plus performant pour faire des pr√©dictions.    \n",
    "Par exemple, si les donn√©es d'entrainement sont normalis√©es par rapport √† leur moyenne et leur √©cart-type, alors les donn√©es test et toute nouvelle donn√©e doivent √™tre normalis√©es par rapport √† la moyenne et l'√©cart-type des donn√©es d'<u>entrainement<u>. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c146f8f-6d56-424d-9eed-bd52789747de",
   "metadata": {},
   "source": [
    "##  2. La fuite de donn√©es "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea01ceaa-3696-4de4-b3f9-0ad687e1a15f",
   "metadata": {},
   "source": [
    "<font size = 4> <span style=\"color:#2980b9\">**Qu'est-ce que c'est ?**</span></font>\n",
    "\n",
    "\n",
    "La fuite de donn√©es se produit lorsque le mod√®le est cr√©√© avec des informations qui ne seront pas pr√©sentes lorsqu'il devra faire des pr√©dictions sur des donn√©es nouvelles. La fuite de donn√©es conduit souvent √† une estimation trop optimiste des performances du mod√®le sur la validation crois√©e ou sur les donn√©es test, par rapport √† ses performances sur des donn√©es r√©ellement nouvelles, en condition r√©elles. \n",
    "\n",
    "<font size = 4><span style=\"color:#2980b9\">**D'o√π elle vient ?**</span></font>\n",
    "\n",
    "\n",
    "- Ne pas s√©parer les donn√©es en sous-ensemble d'entrainement et de test : les donn√©es test doivent pouvoir √™tre consid√©r√©es comme des donn√©es nouvelles, jamais vues par le mod√®le. \n",
    "- Utiliser les donn√©es tests pour s√©lectionner un algorithme ou les param√®tres d'un mod√®le : on ne dispose alors plus de donn√©es ind√©pendantes pour √©valuer les performances du mod√®le final sur des donn√©es \"en conditions r√©elles\"\n",
    "- Appliquer des transformations aux donn√©es test qui ont √©t√© \"apprises\" sur l'ensemble des donn√©es et pas seulement les donn√©es d'entrainement : \n",
    "    - R√®gle num√©ro 1 : **ne jamais appliquer de m√©thode fit sur les donn√©es test**, notamment lors du pr√©-traitement des donn√©es\n",
    "    - les sous-ensemble d'entrainement et de test doivent certes recevoir les m√™mes transformations, mais ces transformations doivent uniquement √™tre apprises sur les donn√©es d'entrainement ! Par exemple, si vous avez une √©tape de normalisation o√π vous divisez par la valeur moyenne, la moyenne doit √™tre la moyenne du sous-ensemble d'entra√Ænement, et **non** la moyenne de toutes les donn√©es. Si le sous-ensemble de test est inclus dans le calcul de la moyenne, les informations du sous-ensemble de test influencent le mod√®le.\n",
    "\n",
    "<font size = 4><span style=\"color:#2980b9\">**Comment l'√©viter ?**</span></font>\n",
    "\n",
    "\n",
    "- S√©parer les donn√©es en sous-ensembles d'entrainement et de tests **AVANT** le pr√©-traitement des donn√©es (erreur TRES couramment retrouv√©e dans la litt√©rature sur les mod√®les ML appliqu√©s √† la physique m√©dicale). \n",
    "- Ne **JAMAIS** appliquer de m√©thode fit() ou fit_transform() aux donn√©es test. Par contre, il faut appliquer la m√©thode transform() aux donn√©es test apr√®s avoir appliqu√© la m√©thode fit() ou fit_transform() aux donn√©es d'entrainement, afin d'appliquer aux donn√©es test les transformations apprises sur les donn√©es d'entrainement, sinon on se retrouve dans l'erreur cit√©e dans la partie 1. \n",
    "- L'utilisation des **pipeline** de scikit learn est le meilleur moyen d'√©viter au maximum les fuites de donn√©es, m√™me pendant la cross-validation : https://scikit-learn.org/stable/modules/compose.html#pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d797840-962d-42c7-8f89-5aca00c6f2bd",
   "metadata": {},
   "source": [
    "## 3. Le contr√¥le de la graine al√©atoire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea1f4c3-95d4-47db-b83b-e95996acb38b",
   "metadata": {},
   "source": [
    "Beaucoup de processus ont un caract√®re al√©atoire intrins√®que comme les algorithmes de ML et la s√©paration des donn√©es lors des cross-validations.    \n",
    "Pour assurer la reproductibilit√© des r√©sultats au cours de plusieurs executions  (utile quand on veut √©valuer l'impact de certains param√®tres, ou lorsque l'on veut publier les r√©sultats), il faut fixer la graine al√©atoire de ces processus. Le mieux est de le faire via le param√®tre random_state = un nombre entier fix√©. D√®s que l'option random_state est disponible pour un processus donn√©, il faut fixer ce param√®tre."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
