{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbeac507-be5f-40dc-b06c-fc30011c76f8",
   "metadata": {},
   "source": [
    "\n",
    "1. D√©finir le probl√®me\n",
    " \n",
    "\n",
    "2. R√©cup√©rer les donn√©es\n",
    " \n",
    "\n",
    "3. **Analyser et nettoyer les donn√©es**\n",
    "  \n",
    "\n",
    "4. Pr√©parer les donn√©es\n",
    "  \n",
    "\n",
    "5. Evaluer plusieurs mod√®les\n",
    "  \n",
    "\n",
    "6. R√©glage fin des mod√®les\n",
    " \n",
    "\n",
    "7. Surveiller son mod√®le"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21096b9-f9e0-4d4a-a16b-be8048a1dc44",
   "metadata": {},
   "source": [
    "# üìå 3. Analyse et Nettoyage des Donn√©es  \n",
    "\n",
    "## üöÄ Objectif\n",
    "Dans cette section, nous allons **analyser et nettoyer** nos donn√©es pour nous assurer qu'elles sont exploitables avant de les utiliser dans un mod√®le de **Machine Learning**.  \n",
    "\n",
    "## üîç √âtapes du processus\n",
    "1. **Importer les biblioth√®ques n√©cessaires**  \n",
    "2. **Charger les donn√©es**  \n",
    "3. **Supprimer les variables non contributives**  \n",
    "   - Variables constantes  \n",
    "   - Variables fortement corr√©l√©es  \n",
    "4. **G√©rer les valeurs aberrantes (outliers)**  \n",
    "5. **Visualiser les donn√©es**  \n",
    "6. **Cat√©goriser les r√©sultats gamma (classification)**  \n",
    "7. **Sauvegarder les bases de donn√©es nettoy√©es**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4492065a-e7b6-4065-825b-bc47aafa947f",
   "metadata": {},
   "source": [
    "## üîπ 3.1. Importation des biblioth√®ques n√©cessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c774a5d9-ea41-4264-82fa-0b9495162cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gestion des avertissements\n",
    "import warnings  # Ignore certains avertissements inutiles lors de l'ex√©cution du code\n",
    "\n",
    "\n",
    "import pandas as pd  # Gestion des DataFrames\n",
    "import numpy as np  # Calculs num√©riques\n",
    "import math  # Fonctions math√©matiques\n",
    "import seaborn as sns  # Graphiques avanc√©s, sert essentiellement √† am√©liorer l'esth√©tique des graphiques\n",
    "import matplotlib.pyplot as plt  # Affichage de graphiques\n",
    "from pandas.plotting import scatter_matrix  # Matrices de nuages de points\n",
    "from sklearn.feature_selection import VarianceThreshold  # Suppression de variables constantes\n",
    "from scipy import stats  # Tests statistiques\n",
    "from numpy import percentile  # Calcul des percentiles\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # D√©sactiver les warnings pour ne pas surcharger l'affichage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461f7d51",
   "metadata": {
    "id": "461f7d51"
   },
   "source": [
    "## üîπ 3.2. Chargement des donn√©es\n",
    "\n",
    "Nous utilisons le fichier **`DataSet_RegionPelvienne.csv`** g√©n√©r√© pr√©c√©demment.  \n",
    "Nous supprimons la colonne `Unnamed: 0` qui correspond aux anciens index inutiles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb64f090",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "id": "fb64f090",
    "outputId": "87d6e113-b103-413e-c69a-fdfb9fe10a39"
   },
   "outputs": [],
   "source": [
    "# Chargement du fichier CSV\n",
    "df = pd.read_csv(\"/content/DataSet_RegionPelvienne.csv\", sep = \",\", header=0)\n",
    "\n",
    "df = df.drop(columns = [\"Unnamed: 0\"]) #Colonne cr√©√©e avec les anciens index. On n'en a pas besoin donc on la supprime directement ici.\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b57da7-9cd8-469a-8ef1-7e2599e3e88d",
   "metadata": {},
   "source": [
    "## üîπ 3.3. Suppression des donn√©es non contributives  \n",
    "\n",
    "Certaines variables **n'apportent pas d'information utile** et peuvent √™tre supprim√©es :\n",
    "1. **Variables constantes** : colonnes avec une variance de 0  \n",
    "2. **Variables fortement corr√©l√©es** : colonnes avec informations redondantes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ppd3qIhLXtW9",
   "metadata": {
    "id": "Ppd3qIhLXtW9"
   },
   "source": [
    "### ‚úÇÔ∏è Suppression des variables constantes  \n",
    "\n",
    "\n",
    "\n",
    "Nous utilisons la m√©thode **`VarianceThreshold()`** pour identifier et supprimer les variables constantes.  \n",
    "Par d√©faut, le seuil est fix√© √† 0 => la m√©thode supprime les colonnes dont la variance est √† 0 => les colonnes de donn√©es constantes. N√©anmoins, on pourrait aussi souhaiter supprimer les colonnes dont les donn√©es varient tr√®s peu donc avec un seuil non nul. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4479a6b-e905-4fe8-ba7f-3a68bea04a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation du filtre de variance\n",
    "vt = VarianceThreshold() #seuillage par d√©faut, pas de modification des param√®tres. \n",
    "\n",
    "# On applique le seuillage d√©fini dans vt √† notre dataframe df avec la m√©thode .fit. \n",
    "_ = vt.fit(df)  # a noter : le _ permet d'acc√©der √† la vol√©e √† la valeur du r√©sultats pr√©c√©dent. Equivalent ici √† vt = vt.fit(df).\n",
    "\n",
    "# Obtention des colonnes non contributives\n",
    "mask = vt.get_support() #m√©thode .get_support() de la classe VarianceThreshold pour obtenir un masque bool√©en des variables s√©lectionn√©es (True si conserv√©es)\n",
    "\n",
    "# Affichage des colonnes supprim√©es\n",
    "print(\"Variables constantes supprim√©es :\", list(df.loc[:, ~mask].columns)) # On affiche les noms des colonnes de donn√©es qui sont constantes (dans une liste pour faciliter l'affichage)\n",
    "print(\"Total :\", len(mask[mask == False])) # On compte le nombre de variables constantes\n",
    "\n",
    "# Suppression des variables constantes\n",
    "df = df.loc[:, mask] #On ne garde que les variables avec une variance diff√©rente de 0\n",
    "\n",
    "# V√©rification du DataFrame apr√®s suppression\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2cda6e-d8cc-4db9-868b-f0bd1ebe6339",
   "metadata": {},
   "source": [
    "### ‚úÇÔ∏è Suppression des variables fortement corr√©l√©es  \n",
    "\n",
    "Les variables **tr√®s corr√©l√©es** apportent la m√™me information et peuvent perturber l'apprentissage du mod√®le (plus il y a de variables plus l'entrainement sera long et le mod√®le risque d'apprendre plus difficilement). Elles peuvent √©galement nuire √† l'interpr√©tation du mod√®le (les variables corr√©l√©es seront utilis√©es al√©atoirement de mani√®re √©quivalente par le mod√®le, ce qui peut diminuer l'importance de chacune d'elle et au final on peut mal interpr√©ter l'importance de ce que d√©crivent ces variables pour le mod√®le quand on cherchera √† comprendre comment il fonctionne).    \n",
    "Nous utilisons le **test de normalit√© de Shapiro-Wilk** pour d√©terminer le test de corr√©lation adapt√© :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a92ec5-22c0-4a3e-92b4-b11f1419ac65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression de la colonne cible pour l'analyse des corr√©lations entre variables\n",
    "variables = df.drop(columns=['Gamma22loc10'])\n",
    "\n",
    "# Test de Shapiro-Wilk\n",
    "for cm in variables.columns: #cm pour \"complexity metric\"\n",
    "    shapiro_test = stats.shapiro(variables[cm])\n",
    "    p = shapiro_test.pvalue\n",
    "\n",
    "    if p_value > 0.05:\n",
    "        print(cm + \" suit une distribution NORMALE (ne rejette pas H0).\")\n",
    "    else:\n",
    "        print(cm + \" non normale (rejette H0).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f02af3-86a3-478d-9e8f-1c1ae76b379d",
   "metadata": {},
   "source": [
    "Le test de Shapiro a tendance √™tre plus adapt√© pour les taille d'√©chantillons moyenne (environ 50-1000 exemples). Ici √† plus de 1300 √©chantillons, le test d'**Agostino-Pearson** aurait aussi pu √™tre adapt√© : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9986711-e9b5-47ae-9431-dadb50676c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de D'Agostino-Pearson\n",
    "for cm in variables.columns:\n",
    "    dagostino_test = normaltest(variables[cm])\n",
    "    p = dagostino_test[1]\n",
    "\n",
    "    if p > 0.05:\n",
    "        print(cm + \" suit une distribution NORMALE (ne rejette pas H0).\")\n",
    "    else:\n",
    "        print(cm + \" non normale (rejette H0).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82edd95e-698f-436b-9ece-a45843204d9c",
   "metadata": {},
   "source": [
    "Et celui de **Anderson-Darling** particuli√®rement adapt√© pour les grands √©chantillons (>1000 exemples) : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873cd10f-be4d-4f3f-a53f-d454fa3d4f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test d'Anderson-Darling\n",
    "for cm in variables.columns:\n",
    "    anderson_test = anderson(variables[cm])\n",
    "    p = 0  # Initialisation de la p-valeur\n",
    "\n",
    "    # D√©terminer la p-valeur en fonction des niveaux de signification\n",
    "    for i in range(len(anderson_test.significance_level)):\n",
    "        if anderson_test.statistic < anderson_test.critical_values[i]:\n",
    "            p = anderson_test.significance_level[i]\n",
    "            break\n",
    "\n",
    "    if p > 0.05:\n",
    "        print(cm + \" suit une distribution NORMALE (ne rejette pas H0).\")\n",
    "    else:\n",
    "        print(cm + \" non normale (rejette H0).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81350f6-9fed-4f9d-9b4b-52432773e1fd",
   "metadata": {},
   "source": [
    "<font size = 4> üî• **Matrice de corr√©lation** </font>    \n",
    "\n",
    "Diff√©rents tests de corr√©lation peuvent √™tre utilis√©s : \n",
    "- **Pearson** : variables continues et normalement distribu√©es\n",
    "- **Spearman** et **Kendall** : variables continues ou ordinales, non n√©cessairement normalement distribu√©es.\n",
    "- **ANOVA** et **Kruskal-Wallis** : variables mixtes, continues (normales pour ANOVA et non normales pour Kruskal Wallis) et cat√©gorielles. \n",
    "\n",
    "\n",
    "Nous utilisons la **corr√©lation de Kendall** pour identifier les variables fortement corr√©l√©es.  \n",
    "Les valeurs > **0.8** indiquent une redondance forte entre deux variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fc50c1-5526-47ca-bbcf-d729d09fd59c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Attention:</b> La cellule ci-dessous ne peut √™tre ex√©cut√©e qu'une seule fois. La 2nde fois, elle affichera une erreur car les colonnes demand√©es ont d√©j√† √©t√© supprim√©es.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c834e26c-9c85-4048-b5e8-72808cdefd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de la matrice de corr√©lation\n",
    "corr_df = variables.corr(method='kendall').abs()\n",
    "\n",
    "# Cr√©ation d'une matrice triangulaire sup√©rieure\n",
    "upper = corr_df.where(np.triu(np.ones(corr_df.shape), k=1).astype(bool))\n",
    "\n",
    "# Index des colonnes avec un indice de corr√©lation >0.8\n",
    "# Possibilit√© de modifier cette valeur pour tester\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.8)]\n",
    "\n",
    "print(\"Variables corr√©l√©es supprim√©es :\", to_drop)\n",
    "print(\"Total :\", len(to_drop))\n",
    "\n",
    "#Pour chaque duo de variables corr√©l√©es, on supprime al√©atoirement l'une des deux variables concern√©es. \n",
    "df = df.drop(columns=to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gKlMi_G_iCO4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "gKlMi_G_iCO4",
    "outputId": "b1c28961-53b2-4a7a-f3dc-56f4cdff52d8"
   },
   "outputs": [],
   "source": [
    "#Affichage d'un extrait de la matrice de corr√©lation\n",
    "#On stocke dans la variable temp quelques unes de nos variables pour l'exemple d'affichage\n",
    "temp = pd.DataFrame(variables, columns =['MUperGy',\n",
    " 'AAV',\n",
    " 'LSV',\n",
    " 'MCS',\n",
    " 'AFW',\n",
    " 'ALT',\n",
    " 'CAS',])\n",
    "corr_temp = temp.corr(method='kendall') #calcul de la matrice de corr√©lation : correlation entre chaque duo de variable dans le dataframe temp\n",
    "plt.figure(figsize=(8, 8)) # on cr√©e une figure\n",
    "# on cr√©e un masque pour ne garder que la moiti√© de la matrice (les r√©sultats apparaissent en double sinon, par exemple AAV vs MCS et MCS vs AAV)\n",
    "# np.triu = triangle sup√©rieur d'un tableau, toutes les donn√©es sous la diagonale du tableau sont pass√©es √† 0\n",
    "# np.ones_like = retourne une matrice de 1 des m√™mes dimensions que la matrice donn√©e en param√®tres. Le dtype force le type des variables de sorties du tableau.\n",
    "mask = np.triu(np.ones_like(corr_temp, dtype=bool)) # tableau de 0 (False) sous la diagonale et de 1 (True) au dessus\n",
    "\n",
    "# Heatmap : carte des valeurs de corr√©lation. Les valeurs ne sont pas affich√©es quand le masque est \"True\". \n",
    "# Les autres param√®tres permettent de r√©gler l'affichage. \n",
    "heatmap = sns.heatmap(corr_temp, mask=mask, vmin=-1, vmax=1, annot=True,annot_kws={\"size\":10}, cmap='BrBG' , linewidth=1, linecolor='w')\n",
    "heatmap.set_title('Matrice de corr√©lation triangulaire', fontdict={'fontsize':18}, pad=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d52bb3-8b9f-4b60-a6d3-7693f315a0d5",
   "metadata": {},
   "source": [
    ">‚ö†Ô∏è **Le coefficient de corr√©lation ne mesure que les corr√©lations lin√©aires (Spearman, Pearson) ou monotones (Kendall) entre les variables.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c1ff60-6130-4018-b63e-35eabe6c08f4",
   "metadata": {},
   "source": [
    "## üîπ 3.4 Gestion des Outliers (valeurs aberrantes des cibles)\n",
    "\n",
    "<font size = 3> üîç **D√©tection** </font>\n",
    "\n",
    "\n",
    "   - **Ecart interquartile** (IQR - Interquartile Range) : on consid√®re qu'une valeur est un outlier si elle est en dehors de l'intervalle `[Q1 - 1.5*IQR, Q3 + 1.5*IQR]` o√π Q1 est le 1er quartile, Q3 le 3√®me quartile et IQR = Q3 - Q1.\n",
    "   - **Z-score** : on consid√®re qu'une valeur est un outlier si sa distance en nombre d'√©cart-types par rapport √† la moyenne est sup√©rieure √† 3.   \n",
    "      $ z = \\frac{x - \\mu}{\\sigma} $ o√π $x$ est la valeur de la donn√©e, $\\mu$ la moyenne de l'ensemble de donn√©es et $\\sigma$ l'√©cart-type de l'ensemble de donn√©e. Si $|z|$>3 alors on consid√®re que la valeur est un outlier. \n",
    "    \n",
    "\n",
    "Les **valeurs aberrantes**  des r√©sultats gamma qui peuvent biaiser l'estimation de la limite de tol√©rance et √©galement l'apprentissage du mod√®le.  Ces valeurs aberrantes peuvent s'expliquer par des probl√®mes au moment de la mesure (panne, d√©rive du d√©tecteur, mauvaise position programm√©e, etc)    \n",
    "Nous utilisons la m√©thode **IQR (Interquartile Range)** pour d√©tecter et supprimer les valeurs extr√™mes. Cependant, comme les valeurs gamma hors tol√©rance sont rares et que ce sont elles que l'on veut sp√©cifiquement d√©tecter, il faut faire attention √† ne pas supprimer les valeurs avec un seuil trop bas. Nous avons donc choisi d'utiliser la m√©thode IQR mais avec un seuil √† `6*IQR`. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd032db9-e23b-4bc0-84a2-4c37743ac412",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Attention:</b> La cellule ci-dessous ne peut √™tre ex√©cut√©e qu'une seule fois. La 2nde fois, elle n'affichera pas d'erreur mais elle va multiplier les indices gamma une seconde fois par 100 et d√©finir un nouveau seuil de coupure. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4399a51d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4399a51d",
    "outputId": "adf2397c-2798-445d-9a8c-28f1228ad5e0"
   },
   "outputs": [],
   "source": [
    "# Conversion des indices gamma en pourcentage\n",
    "df.Gamma22loc10 = df.Gamma22loc10*100\n",
    "\n",
    "# Calcul du 1er et 3√®me quartile\n",
    "q25, q75 = percentile(df.Gamma22loc10, 25), percentile(df.Gamma22loc10, 75)\n",
    "\n",
    "# Calcul de l'√©cart interquartile (IQR)\n",
    "iqr = q75 - q25\n",
    "\n",
    "#On affiche les r√©sultats\n",
    "print('Percentiles: 25th=%.3f, 75th=%.3f, IQR=%.3f' % (q25, q75, iqr))\n",
    "\n",
    "# D√©finition d'un seuil de coupure pour d√©tecter les outliers : on a choisi ici 6*iqr\n",
    "cut_off = iqr * 6\n",
    "lower, upper = q25 - cut_off, q75 + cut_off\n",
    "print(\"cut off = \", cut_off)\n",
    "\n",
    "#On d√©finit les cutoff sup et inf\n",
    "lower, upper = q25 - cut_off, q75 + cut_off\n",
    "\n",
    "print(\"lower cut off = \", lower)\n",
    "\n",
    "# Identification des outliers\n",
    "outliers = [x for x in df.Gamma22loc10 if x < lower or x > upper]\n",
    "\n",
    "print('outliers identifi√©s : %d' % len(outliers))\n",
    "\n",
    "# suppression des outliers\n",
    "outliers_removed = [x for x in df.Gamma22loc10 if x >= lower and x <= upper]\n",
    "\n",
    "print('Observations non outliers: %d' % len(outliers_removed))\n",
    "\n",
    "df = df[df.Gamma22loc10>= lower]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b850726b-9f7a-4fce-a05a-96b76f4c0f85",
   "metadata": {},
   "source": [
    "## üîπ 3.5 Visualisation des Donn√©es  \n",
    "\n",
    "### üî¶ Corr√©lation des variables avec les cibles  \n",
    "\n",
    "Nous affichons les variables **les plus corr√©l√©es** avec `Gamma22loc10`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ab30c1-e5b8-4e49-b1f0-057799704f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de la matrice de corr√©lation\n",
    "matrice_corr = df.corr(method='kendall').abs()\n",
    "\n",
    "# Affichage des 20 variables les plus corr√©l√©es avec Gamma22loc10\n",
    "matrice_corr[\"Gamma22loc10\"].sort_values(ascending=False).head(21)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "l8HsiXy_00gM",
   "metadata": {
    "id": "l8HsiXy_00gM"
   },
   "source": [
    ">‚ö†Ô∏è **Le coefficient de corr√©lation ne mesure que les corr√©lations lin√©aires (Spearman, Pearson) ou monotones (Kendall) entre les variables.**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992e19f1-46a1-4990-8bae-75a4a9e6c9f6",
   "metadata": {},
   "source": [
    "### üìä Distribution des variables  \n",
    "Nous tra√ßons les **distributions des variables les plus importantes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SgcATWZn3bKE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 709
    },
    "id": "SgcATWZn3bKE",
    "outputId": "1e7b7280-0de1-454f-c577-31b5fa0b832f"
   },
   "outputs": [],
   "source": [
    "# S√©lection des variables pour la visualisation\n",
    "attributs = [\"Gamma22loc10\", \"EM\", \"BI\", \"EMmin\", \"BIiqr\", \"BImax\", \"BIstd\"]\n",
    "\n",
    "# Matrice de nuages de points\n",
    "scatter_matrix(df[attributs], figsize=(15, 8), diagonal='kde')\n",
    "\n",
    "# Ajustement des axes\n",
    "for i in range(1, 7):\n",
    "    plt.gca().set_ylim(95, 100)\n",
    "    plt.gca().set_xlim(95, 100)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b882e618-afc9-4be6-90d2-db4b63bee5cf",
   "metadata": {},
   "source": [
    "## üîπ 3.6 Cat√©gorisation des r√©sultats PSQA  \n",
    "\n",
    "Nous devons transformer `Gamma22loc10` en **classe binaire** pass/fail pour la classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99eed0a",
   "metadata": {
    "id": "b99eed0a"
   },
   "source": [
    "### üîß Binarisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e05109-54d9-492d-87ae-0736b38e8e47",
   "metadata": {},
   "source": [
    "<span style=\"color:#2980b9\"> **1. On d√©finit un seuil pour la binarisation** </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de594524",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 546
    },
    "id": "de594524",
    "outputId": "ccfc2514-308c-4dc5-ae47-bf8337e1b11e"
   },
   "outputs": [],
   "source": [
    "# On d√©finit un seuil, par exemple le 10√®me percentile de la distribution de gamma\n",
    "seuil = np.percentile(df.Gamma22loc10, 10)\n",
    "\n",
    "#Affichage de la distribution\n",
    "gamma = df.Gamma22loc10\n",
    "plt.figure(figsize=(12,6))\n",
    "g = sns.displot(gamma)\n",
    "plt.xlabel(\"GPR\", size=14)\n",
    "plt.ylabel(\"Nombre d'exemples\", size=14)\n",
    "plt.axvline(x=seuil,color='red',linestyle='dashed',linewidth=1, label='Percentile')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left', prop={'size': 12})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a44e92-4c55-43b3-a3d2-efc4a1779244",
   "metadata": {},
   "source": [
    "<span style=\"color:#2980b9\"> **2. On attribue 1 aux observations sous le seuil (celles que l'on veut pr√©dire) et 0 √† celles au-dessus** </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a838f746-aa03-4901-b8ed-ab92891ee0af",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Attention:</b> La cellule ci-dessous ne peut √™tre ex√©cut√©e qu'une seule fois. La 2nde fois, elle √©crasera l'enregistrement de df avant binarisation et renverra une erreur car la colonne Gamma22loc10 a √©t√© supprim√©e\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f4bf46",
   "metadata": {
    "id": "55f4bf46"
   },
   "outputs": [],
   "source": [
    "# Binarisation\n",
    "# Ajout d'une colonne nomm√©e Echec dans laquelle les indices gamma <=seuil sont pass√©s √† 1 (classe positive, 'fail'), et ceux >LCLx √† 0 (classe n√©gative, 'pass')\n",
    "df = df.assign(Echec=pd.cut(df.Gamma22loc10,\n",
    "                               bins=[0, seuil, 100],\n",
    "                               labels=[1, 0]))\n",
    "\n",
    "# Suppression de la colonne des indices gamma\n",
    "df = df.drop(columns=[\"Gamma22loc10\"])\n",
    "\n",
    "# Attribution du type \"int\" √† la colonne Echec qui contient des 0 et des 1. \n",
    "df['Echec'] = df.Echec.astype('int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae3dc7a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5ae3dc7a",
    "outputId": "6ed72468-2462-4243-bb0b-a8ab57f36dd8"
   },
   "outputs": [],
   "source": [
    "#Visualisation des donn√©es\n",
    "fig = df.hist(xlabelsize=5, ylabelsize=5,figsize=(13,17) )\n",
    "[x.title.set_size(10) for x in fig.ravel()]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NLw59qIjtoa1",
   "metadata": {
    "id": "NLw59qIjtoa1"
   },
   "source": [
    "<font size = 4>üìä Informations que l'on peut extraire de ces histogrammes :</font>\n",
    "\n",
    "\n",
    "* **Diff√©rences d'echelles** entre les variables\n",
    "* **Forme des distributions** : plusieurs distributions sont fortement dissym√©triques.\n",
    "\n",
    "Ces deux param√®tres peuvent nuire aux performances des mod√®les.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56140aaa",
   "metadata": {
    "id": "56140aaa"
   },
   "source": [
    "## üíæ 3.6 Sauvegarde des donn√©es "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9db413",
   "metadata": {
    "id": "bf9db413"
   },
   "outputs": [],
   "source": [
    "# Sauvegarde du fichier CSV apr√®s binarisation\n",
    "df.to_csv('DataSet_RegionPelvienne_Class.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b088bf99-90b6-43f0-86ec-60e1f3269814",
   "metadata": {
    "id": "1eiu5c5thISy"
   },
   "source": [
    "üìå **Un fichier CSV a √©t√© cr√©√© et est pr√™t pour les prochaines √©tapes du projet** üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ed76d2-e243-48fd-aee7-13e3bd4a8b2d",
   "metadata": {},
   "source": [
    "<font size = 6>‚ö†Ô∏è</font> \n",
    "\n",
    "**T√©l√©charger le fichier**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
