{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2bc91f8d-244c-493f-a4b3-8a07226cad7d",
   "metadata": {},
   "source": [
    "\n",
    "1. D√©finir le probl√®me\n",
    " \n",
    "\n",
    "2. R√©cup√©rer les donn√©es\n",
    " \n",
    "\n",
    "3. Analyser et nettoyer les donn√©es\n",
    "  \n",
    "\n",
    "4. **Pr√©parer les donn√©es**\n",
    "  \n",
    "\n",
    "5. Evaluer plusieurs mod√®les\n",
    "  \n",
    "\n",
    "6. R√©glage fin des mod√®les\n",
    " \n",
    "\n",
    "7. Surveiller son mod√®le\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb72d37-7515-4f7f-beb5-cdd4012d3a33",
   "metadata": {},
   "source": [
    "# üìå 4. Pr√©paration des donn√©es pour les algorithmes d'apprentissage  \n",
    "\n",
    "## üöÄ Objectif\n",
    "Avant d'entra√Æner nos mod√®les de Machine Learning, nous devons **pr√©parer les donn√©es** pour garantir de **bonnes performances** et √©viter les biais.\n",
    "\n",
    "## üîç √âtapes du processus\n",
    "1. **Import des donn√©es**  \n",
    "2. **S√©paration des donn√©es** (train/test)  \n",
    "3. **R√©-√©quilibrage des classes**  \n",
    "4. **Calibrage des variables** (normalisation, standardisation)  \n",
    "5. **S√©lection des variables** (r√©duction de dimension)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f439ac6-5954-4145-a182-f933c765d0db",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.prod.website-files.com/6064b31ff49a2d31e0493af1/668517f547fb76e5a91026bd_AD_4nXcwTG4Tw3E2nZxeQud4AA2MU6q2KLoeTSLdjDT5lTaNKS681rs4O4_0gxtXt0DhRdvOSAfHmL6UK1q0AubR5NAZsEhT-MsIOf5bohGePloG-k8pnLcHuVauADJyLJRL3t14b1DaWceY5sb-q2joEJqBlZ4S.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d1d3ec-2d78-43c8-9232-fa8cfb9baf54",
   "metadata": {},
   "source": [
    "## üîπ 4.1. Importation des biblioth√®ques n√©cessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6b6304-f963-4831-9eff-c80a456eca70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des biblioth√®ques n√©cessaires\n",
    "\n",
    "# Gestion des avertissements\n",
    "import warnings  # Ignore certains avertissements inutiles lors de l'ex√©cution du code\n",
    "\n",
    "# Manipulation et analyse de donn√©es\n",
    "import pandas as pd  # Manipulation de tableaux de donn√©es (√©quivalent de SQL ou Excel en Python)\n",
    "import numpy as np  # Calculs scientifiques et manipulation de matrices\n",
    "import math  # Fonctions math√©matiques avanc√©es\n",
    "\n",
    "# Visualisation des donn√©es\n",
    "import matplotlib.pyplot as plt  # Cr√©ation de graphiques et visualisations\n",
    "import seaborn as sns  # Am√©liore l'esth√©tique des graphiques Matplotlib\n",
    "\n",
    "# Scikit-learn : biblioth√®que de Machine Learning\n",
    "\n",
    "## Gestion des ensembles d'entra√Ænement et de test\n",
    "from sklearn.model_selection import train_test_split  # S√©pare les donn√©es en ensemble d'entra√Ænement et de test\n",
    "from sklearn.model_selection import GridSearchCV  # Optimisation des hyperparam√®tres via une recherche sur grille\n",
    "from sklearn.model_selection import cross_val_score  # √âvaluation du mod√®le via validation crois√©e\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, StratifiedKFold  \n",
    "# Divise les donn√©es en sous-groupes pour validation crois√©e tout en respectant la r√©partition des classes\n",
    "\n",
    "## √âvaluation des mod√®les\n",
    "from sklearn.metrics import confusion_matrix  # Matrice de confusion pour analyser les erreurs du mod√®le\n",
    "from sklearn.metrics import balanced_accuracy_score  # Score d'exactitude pond√©r√© pour donn√©es d√©s√©quilibr√©es\n",
    "from sklearn.metrics import roc_curve  # Courbe ROC pour √©valuer les performances des mod√®les binaires\n",
    "from sklearn.metrics import average_precision_score  # Moyenne de la pr√©cision pour √©valuer un classifieur\n",
    "from sklearn.metrics import make_scorer  # Cr√©ation de m√©triques personnalis√©es\n",
    "from sklearn.metrics import roc_auc_score  # Calcul de l'aire sous la courbe ROC (AUC)\n",
    "from sklearn.metrics import precision_recall_curve  # Courbe pr√©cision-rappel pour l'analyse des performances\n",
    "\n",
    "## Pipelines et pr√©traitement des donn√©es\n",
    "from sklearn.pipeline import Pipeline  # Automatisation du processus de transformation et d'entra√Ænement des mod√®les\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler  \n",
    "# StandardScaler : centre et r√©duit les donn√©es (moyenne=0, √©cart-type=1)\n",
    "# MinMaxScaler : met les donn√©es √† l‚Äô√©chelle entre 0 et 1\n",
    "\n",
    "## S√©lection des variables\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif, RFECV  \n",
    "# SelectKBest : s√©lectionne les k meilleures variables en fonction d'un crit√®re\n",
    "# mutual_info_classif : s√©lectionne les variables selon l'information mutuelle avec la cible\n",
    "# RFECV : √©limination r√©cursive des variables avec validation crois√©e\n",
    "\n",
    "## R√©duction de dimension\n",
    "from sklearn.decomposition import PCA  # Analyse en Composantes Principales (PCA) pour r√©duire le nombre de variables\n",
    "\n",
    "## Algorithmes de Machine Learning\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier  \n",
    "# RandomForestClassifier : ensemble d'arbres de d√©cision pour classification\n",
    "# GradientBoostingClassifier : algorithme ensembliste qui am√©liore les pr√©dictions par it√©ration\n",
    "# AdaBoostClassifier : m√©thode de boosting qui pond√®re les erreurs des pr√©dictions pr√©c√©dentes\n",
    "\n",
    "from sklearn.svm import SVC  # Machine √† Vecteurs de Support (SVM) pour classification\n",
    "from sklearn.linear_model import LogisticRegression  # R√©gression logistique pour classification binaire\n",
    "from sklearn.neighbors import KNeighborsClassifier  # Classifieur bas√© sur la distance aux k plus proches voisins\n",
    "from sklearn.naive_bayes import GaussianNB  # Classifieur bas√© sur le th√©or√®me de Bayes (version gaussienne)\n",
    "from sklearn.neural_network import MLPClassifier  # R√©seau de neurones de type perceptron multicouche\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis # Analyse discriminante quadratique\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis # Analyse discriminante lin√©aire\n",
    "\n",
    "## Gestion du d√©s√©quilibre des classes\n",
    "from imblearn.under_sampling import RandomUnderSampler  # Sous-√©chantillonnage al√©atoire pour √©quilibrer les classes\n",
    "\n",
    "# Widgets interactifs pour Jupyter Notebook / JupyterLab\n",
    "import ipywidgets as widgets  # Cr√©ation d'interfaces interactives dans un Notebook\n",
    "from IPython.display import display  # Affichage interactif des widgets et des sorties\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7jF8v2f5IJH2",
   "metadata": {
    "id": "7jF8v2f5IJH2",
    "tags": []
   },
   "source": [
    "## üîπ 4.2. Import des donn√©es\n",
    "\n",
    "Nous utilisons le fichier **`DataSet_RegionPelvienne_Class.csv`** contenant notre jeu de donn√©es apr√®s nettoyage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c84e17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "f9c84e17",
    "outputId": "afdb30b6-3ac7-482a-cc06-ee5e2ee0bfe9"
   },
   "outputs": [],
   "source": [
    "# Chargement du fichier CSV\n",
    "df = pd.read_csv(\"/content/DataSet_RegionPelvienne_Class.csv\", sep=\",\", header=0)\n",
    "\n",
    "# Suppression de la colonne d'index inutile\n",
    "df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "# Affichage des 5 premi√®res lignes pour v√©rification\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d597cd7",
   "metadata": {
    "id": "0d597cd7"
   },
   "source": [
    "## üîπ 4.3. S√©paration des donn√©es\n",
    "\n",
    "Nous devons diviser nos donn√©es en **jeu d'entra√Ænement** et **jeu de test** :\n",
    "- **70-80% pour l'entra√Ænement**\n",
    "- **20-30% pour le test** \n",
    "- **Stratification** pour conserver la r√©partition des classes  \n",
    "- **Fixation de la graine al√©atoire** pour garantir la reproductibilit√© \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e0153c-0e2a-4a78-b003-82079ac68052",
   "metadata": {},
   "source": [
    "<img src=\"https://www.researchgate.net/publication/325870973/figure/fig6/AS:639531594285060@1529487622235/Train-Test-Data-Split.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331d6702-bba0-4aa7-b767-d0cf244b4d48",
   "metadata": {},
   "source": [
    "\n",
    "<font size=\"8\"> ‚ö†Ô∏è </font> <font size=\"5\"> <span style=\"color:#f0290e\">**jeu de test** : </span> </font>\n",
    "* **Jamais** utilis√© pendant l'apprentissage, uniquement utilis√© pour √©valuer les performances du mod√®le **final**.\n",
    "* **Repr√©sentatif** des donn√©es de la vie r√©elle (notamment : r√©partition des donn√©es)\n",
    "* Il va servir √† calculer l'**erreur de g√©n√©ralisation** : la capacit√© de notre mod√®le √† faire des pr√©dictions correctes √† partir de donn√©es inconnues.\n",
    "* On choisit au hasard **entre 20 et 30%** des √©l√©ments du jeu de donn√©es.\n",
    "* Il faut faire attention √† bien **fixer la graine al√©atoire** lors de la division des donn√©es pour ne pas g√©n√©rer un jeu de test diff√©rent √† chaque execution de la cellule ! Sinon au fur et √† mesure l'ensemble du jeu de donn√©es aura √©t√© utilis√© pour l'apprentissage et l'√©valuation de la g√©n√©ralisation sera biais√©e alors que c'est ce qu'on cherche justement √† √©viter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283bbbba",
   "metadata": {
    "id": "283bbbba"
   },
   "outputs": [],
   "source": [
    "# S√©paration de la variable cible et des variables explicatives\n",
    "y = pd.DataFrame( df['Echec'])\n",
    "z = df.drop('Echec', axis = 1)\n",
    "\n",
    "# S√©paration en train/test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(z,y, test_size = 0.3,stratify=y, random_state=2025)\n",
    "\n",
    "# R√©initialisation des index des lignes dans chaque jeu\n",
    "X_train = X_train.reset_index(drop=True) \n",
    "Y_train = Y_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "Y_test = Y_test.reset_index(drop=True)\n",
    "\n",
    "# V√©rification de la r√©partition des classes\n",
    "print(\"R√©partition des classes dans le set d'entra√Ænement :\")\n",
    "print(Y_train.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nR√©partition des classes dans le set de test :\")\n",
    "print(Y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7d11a7",
   "metadata": {
    "id": "2b7d11a7"
   },
   "source": [
    "## üîπ 4.4. R√©-√©quilibrage des classes  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d00dcb-8bcc-4de1-9d10-35e8df3c4e10",
   "metadata": {},
   "source": [
    "<img src=\"https://www.lexplicite.fr/wp-content/uploads/2016/03/balance.jpg\" alt=\"drawing\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbab6aa3-69b3-4e4a-b9a9-7e0443a26df3",
   "metadata": {},
   "source": [
    "Notre jeu de donn√©es pr√©sente un **d√©s√©quilibre** :  \n",
    "- **90% de r√©ussite**  \n",
    "- **10% d‚Äô√©chec**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82243ec8-4480-48c8-b6ee-460c618a5676",
   "metadata": {},
   "source": [
    "### ‚ö†Ô∏è Pourquoi est-ce un probl√®me ?  \n",
    "En classification, un **d√©s√©quilibre de classes** peut poser un probl√®me majeur :  \n",
    "Les algorithmes ont tendance √† **favoriser la classe majoritaire**, car elle est **statistiquement plus pr√©sente** dans les donn√©es d‚Äôentra√Ænement.  \n",
    "Cela peut √™tre probl√©matique si la **classe minoritaire est celle qui nous int√©resse le plus**, comme ici avec la classe \"√©chec\" que nous souhaitons pr√©dire. \n",
    "\n",
    "\n",
    "Si un algorithme est entra√Æn√© sur un dataset o√π **90% des observations appartiennent √† la classe majoritaire**, il pourrait atteindre **90% de pr√©cision** simplement en **pr√©disant toujours la classe majoritaire**, **sans jamais d√©tecter la classe minoritaire** !  \n",
    "‚û° **Cela fausse compl√®tement l‚Äôapprentissage et les performances du mod√®le.**  \n",
    "\n",
    "### üî• Solutions pour g√©rer le d√©s√©quilibre des classes  \n",
    "\n",
    "\n",
    "| M√©thode               | Fonction Scikit-learn | Principe | Inconv√©nients |\n",
    "|-----------------------|----------------------|-----------|--------------|\n",
    "| **Sur-√©chantillonnage de la classe minoritaire** | `SMOTE()` | Augmente la classe minoritaire artificiellement| Exemples artificiels parfois peu r√©alistes |\n",
    "| **Sous-√©chantillonnage de la classe majoritaire** | `RandomUnderSampler()` | Diminue la classe majoritaire en supprimant des exemples| Risque de perte d'information |\n",
    "| **Combinaison du sur-√©chantillonnage et du sous-√©chantillonnage** | `SMOTEENN()` | G√©n√®re des exemples artificiels de la classe minoritaire et supprime des exemples de la classe majoritaire | Complexit√© accrue |\n",
    "| **Apprentissage sensible au co√ªt** | `class_weight='balanced'` | Ajuste l'importance des classes dans l‚Äôalgorithme d‚Äôapprentissage en pond√©rant la classe minoritaire, sans modifier les donn√©es. | D√©pend de l'algorithme |\n",
    "\n",
    "\n",
    "\n",
    "Il n‚Äôexiste **pas de solution unique**, tout d√©pend des donn√©es que nous voulons traiter.   \n",
    "üëâ Il faut tester plusieurs approches et comparer les performances. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f822e77-5f37-484e-8d89-8f71e16348c2",
   "metadata": {},
   "source": [
    "<img src=\"https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10115-022-01772-8/MediaObjects/10115_2022_1772_Fig1_HTML.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f11bb21",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0f11bb21",
    "outputId": "c1df5dee-e9b5-4b3f-eb58-d3de30c53371"
   },
   "outputs": [],
   "source": [
    "# Application du sous-√©chantillonnage de la classe majoritaire\n",
    "# Il est possible de moduler le sous-√©chantillonnage pour seulement r√©duire le d√©s√©quilibre sans pour autant l'annuler compl√®tement en modifiant le param√®tre \"sampling_strategy\"\n",
    "# Ici on ne supprime pas totalement le d√©s√©quilibre pour ne pas supprimer trop d'information\n",
    "rus = RandomUnderSampler(sampling_strategy={\n",
    "        0: len(Y_train[Y_train.Echec==1])*2,\n",
    "        1: len(Y_train[Y_train.Echec==1])\n",
    "    }, random_state=2025)\n",
    "\n",
    "X_train_res, Y_train_res = rus.fit_resample(X_train, Y_train)\n",
    "\n",
    "# Transformation des donn√©es en DataFrame pour simplifier la manipulation\n",
    "X_train_res = pd.DataFrame(X_train_res, columns = z.columns)\n",
    "\n",
    "\n",
    "# V√©rification apr√®s r√©-√©quilibrage\n",
    "print(Y_train_res.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6baa6d-afc2-43f4-adf2-652035f1c0b3",
   "metadata": {},
   "source": [
    "<font size=\"5\"> **‚ö†Ô∏è Attention** </font>    \n",
    "On ne r√©√©chantillonne que les donn√©es d'entrainement pour aider le mod√®le √† apprendre √† pr√©dire la classe minoritaire.   \n",
    "**Les donn√©es test ne sont pas r√©√©chantillonn√©es**, elles doivent rester repr√©sentatives de la r√©partition des donn√©es dans le monde r√©el. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfcc745-36fc-4e9f-b7fd-5dd00b1b04fa",
   "metadata": {},
   "source": [
    "## üîπ 4.5. Calibrage des variables  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e477d4-5ab1-4251-b9fa-c29d968507b6",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn-blog.scalablepath.com/uploads/2023/09/data-preprocessing-techiniques-data-transformation-1-edited.png\" alt=\"drawing\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7547dfd6-9ff5-44d0-a970-4ff9e704511d",
   "metadata": {},
   "source": [
    "Beaucoup d'algorithmes fonctionnent mieux lorsque les variables sont sur **la m√™me √©chelle**.  \n",
    "\n",
    "<font size=\"4\"> **üî© Deux m√©thodes courantes de calibrage** </font>\n",
    "1. **Min-Max Scaling** : Met les valeurs entre 0 et 1 (sensible aux outliers), utile pour les r√©seaux de neurones notamment.   \n",
    "     scikit : `MinMaxScaler()`\n",
    "3. **Standardisation (Z-score)** : Centre les valeurs autour de 0 avec un √©cart-type de 1 (plus robuste).   \n",
    "     scikit : `StandardScaler()`\n",
    "\n",
    "<font size=\"5\">‚ö†Ô∏è</font> **IMPORTANT** :  \n",
    "Les param√®tres de transformation doivent √™tre **calcul√©s uniquement sur les donn√©es d'entra√Ænement** et **appliqu√©s aux donn√©es test**.  \n",
    "‚ùå **Ne jamais faire `fit()` ou `fit_transform()` sur les donn√©es test !**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5475a66a-4cee-441a-838a-6d565c42b1d1",
   "metadata": {},
   "source": [
    "<font size=\"4\"> **üóÑÔ∏è Encodage des variables cat√©gorielles** </font> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317a3f57-3b58-4215-9b0b-af87cf148602",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*oU6w-wS25ySA4liGSESOHA.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3eef19-d2cf-4899-bbf2-45ac00179358",
   "metadata": {},
   "source": [
    "Une √©tape de transformation suppl√©mentaire est parfois appliqu√©e : l'**encodage des variables cat√©gorielles**      \n",
    "Si la base de donn√©es contient des **variables cat√©gorielles**, elles doivent √™tre converties en **valeurs num√©riques** :  \n",
    "\n",
    "‚úî **Variables ordinales** (avec un ordre) : on attribue une valeur respectant l'ordre.   \n",
    " Ex: `'Low' = 1`, `'Medium' = 2`, `'High' = 3`  \n",
    "\n",
    "‚úî **Variables nominales** (sans ordre) :  on cr√©e n variables binaires qui d√©crivent chacune une des n cat√©gories de la variable d'origine. Par exemple si on a une variable \"Localisation tumorale\" qui d√©crit la localisation du cancer en cat√©gories \"Prostate\" \"Uterus\" \"Sein\" \"Poumon\", on cr√©era 4 variables binaires nomm√©es \"Prostate, \"Uterus\", \"Sein\", \"Poumon\"; La variable \"Prostate\" sera √©gale √† 1 si la ligne concern√©e de la base de donn√©es est issue de cette localisation et 0 sinon. Idem pour les 3 autres localisations.   \n",
    "  `One-Hot Encoding()` de scikit permet de le faire automatiquement. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28b2dbc-6cb2-48eb-9d49-d47c3ccd4d0b",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*x_DYdNVsPiRoDpSoRGJo3Q.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ab2109-c05b-44a8-a71a-e598f413b500",
   "metadata": {},
   "source": [
    "<font size=\"4\"> **üõ†Ô∏è Power Transformer Scaler** </font>  \n",
    "\n",
    "\n",
    "Certains algortihmes fonctionnent mieux avec des donn√©es distribu√©es normalement (r√©gression logistique, analyse discriminante lin√©aire, KNN, SVM). \n",
    "\n",
    "üìå **Transformation** : Applique une transformation logarithmique pour **rendre les donn√©es plus normales** et r√©duire l'effet des valeurs extr√™mes.  \n",
    "\n",
    "üìå **Utile pour** : Donn√©es **tr√®s asym√©triques** ou avec une **distribution exponentielle**.  \n",
    "\n",
    "üìå **Deux m√©thodes disponibles** :  \n",
    "- **Box-Cox** : Fonctionne uniquement sur des donn√©es **strictement positives** (scikit : `PowerTransformer(method='box-cox')`).  \n",
    "- **Yeo-Johnson** : Peut √™tre appliqu√© aux donn√©es **positives et n√©gatives** (scikit : `PowerTransformer(method='yeo-johnson')`).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5f48ae-4b49-4bce-a08e-5d9c4f6fffd5",
   "metadata": {},
   "source": [
    "‚û°Ô∏è Pour notre exemple, pour simplifier, on applique simplement une standardisation\n",
    "* Pour chaque variable : on soustrait la valeur moyenne et on divise par l'√©cart-type.\n",
    "* Les valeurs recalibr√©es auront une moyenne nulle et un √©cart-type √©gal √† 1.\n",
    "* Les valeurs ne sont pas limit√©es √† un intervalle (peut poser probl√®me pour les r√©seaux de neurones qui attendent souvent des valeurs entre 0 et 1) mais  le r√©sultat est beaucoup moins sensible aux valeurs aberrantes qui peuvent √©craser les autres valeurs dans une transformation min-max.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9fBx8pFXWblJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "9fBx8pFXWblJ",
    "outputId": "627728f9-3eaf-4150-c179-743ef090fbfc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MUperGy</th>\n",
       "      <th>MUmax</th>\n",
       "      <th>MUstd</th>\n",
       "      <th>MUiqr</th>\n",
       "      <th>AAV</th>\n",
       "      <th>AAVmin</th>\n",
       "      <th>AAVmax</th>\n",
       "      <th>AAVstd</th>\n",
       "      <th>AAViqr</th>\n",
       "      <th>LSV</th>\n",
       "      <th>...</th>\n",
       "      <th>EMstd</th>\n",
       "      <th>EMiqr</th>\n",
       "      <th>MIt02</th>\n",
       "      <th>BI</th>\n",
       "      <th>BImin</th>\n",
       "      <th>BImax</th>\n",
       "      <th>BIstd</th>\n",
       "      <th>BIiqr</th>\n",
       "      <th>BM</th>\n",
       "      <th>BAmin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.090000e+02</td>\n",
       "      <td>3.090000e+02</td>\n",
       "      <td>3.090000e+02</td>\n",
       "      <td>3.090000e+02</td>\n",
       "      <td>3.090000e+02</td>\n",
       "      <td>3.090000e+02</td>\n",
       "      <td>3.090000e+02</td>\n",
       "      <td>3.090000e+02</td>\n",
       "      <td>3.090000e+02</td>\n",
       "      <td>3.090000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>3.090000e+02</td>\n",
       "      <td>3.090000e+02</td>\n",
       "      <td>3.090000e+02</td>\n",
       "      <td>3.090000e+02</td>\n",
       "      <td>3.090000e+02</td>\n",
       "      <td>3.090000e+02</td>\n",
       "      <td>3.090000e+02</td>\n",
       "      <td>3.090000e+02</td>\n",
       "      <td>3.090000e+02</td>\n",
       "      <td>3.090000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.184517e-16</td>\n",
       "      <td>-9.341682e-17</td>\n",
       "      <td>-2.012055e-16</td>\n",
       "      <td>-7.185910e-17</td>\n",
       "      <td>-2.299491e-16</td>\n",
       "      <td>-4.598982e-17</td>\n",
       "      <td>-3.794160e-16</td>\n",
       "      <td>2.012055e-16</td>\n",
       "      <td>1.149746e-16</td>\n",
       "      <td>2.230506e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.299491e-17</td>\n",
       "      <td>-1.609644e-16</td>\n",
       "      <td>-5.173855e-16</td>\n",
       "      <td>2.069542e-16</td>\n",
       "      <td>-3.104313e-16</td>\n",
       "      <td>-5.403804e-16</td>\n",
       "      <td>1.897080e-16</td>\n",
       "      <td>-2.471953e-16</td>\n",
       "      <td>2.299491e-17</td>\n",
       "      <td>1.839593e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.001622e+00</td>\n",
       "      <td>1.001622e+00</td>\n",
       "      <td>1.001622e+00</td>\n",
       "      <td>1.001622e+00</td>\n",
       "      <td>1.001622e+00</td>\n",
       "      <td>1.001622e+00</td>\n",
       "      <td>1.001622e+00</td>\n",
       "      <td>1.001622e+00</td>\n",
       "      <td>1.001622e+00</td>\n",
       "      <td>1.001622e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.001622e+00</td>\n",
       "      <td>1.001622e+00</td>\n",
       "      <td>1.001622e+00</td>\n",
       "      <td>1.001622e+00</td>\n",
       "      <td>1.001622e+00</td>\n",
       "      <td>1.001622e+00</td>\n",
       "      <td>1.001622e+00</td>\n",
       "      <td>1.001622e+00</td>\n",
       "      <td>1.001622e+00</td>\n",
       "      <td>1.001622e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.896033e+00</td>\n",
       "      <td>-9.007779e-01</td>\n",
       "      <td>-9.811186e-01</td>\n",
       "      <td>-9.062054e-01</td>\n",
       "      <td>-2.605130e+00</td>\n",
       "      <td>-2.493933e+00</td>\n",
       "      <td>-2.793264e+00</td>\n",
       "      <td>-1.962361e+00</td>\n",
       "      <td>-1.692180e+00</td>\n",
       "      <td>-4.227638e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.911521e+00</td>\n",
       "      <td>-1.704696e+00</td>\n",
       "      <td>-1.926156e+00</td>\n",
       "      <td>-1.820530e+00</td>\n",
       "      <td>-1.404660e+00</td>\n",
       "      <td>-1.739618e+00</td>\n",
       "      <td>-1.504247e+00</td>\n",
       "      <td>-9.955593e-01</td>\n",
       "      <td>-3.974558e+00</td>\n",
       "      <td>-1.307684e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.506351e-01</td>\n",
       "      <td>-6.155379e-01</td>\n",
       "      <td>-6.331584e-01</td>\n",
       "      <td>-5.665571e-01</td>\n",
       "      <td>-6.611972e-01</td>\n",
       "      <td>-7.262604e-01</td>\n",
       "      <td>-7.476646e-01</td>\n",
       "      <td>-7.570348e-01</td>\n",
       "      <td>-7.360150e-01</td>\n",
       "      <td>-6.834335e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.476983e-01</td>\n",
       "      <td>-7.664314e-01</td>\n",
       "      <td>-8.200404e-01</td>\n",
       "      <td>-7.337534e-01</td>\n",
       "      <td>-7.380765e-01</td>\n",
       "      <td>-7.256489e-01</td>\n",
       "      <td>-5.434622e-01</td>\n",
       "      <td>-4.022145e-01</td>\n",
       "      <td>-6.025596e-01</td>\n",
       "      <td>-7.269936e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.134193e-02</td>\n",
       "      <td>-3.821247e-01</td>\n",
       "      <td>-2.785735e-01</td>\n",
       "      <td>-3.094307e-01</td>\n",
       "      <td>-6.571037e-02</td>\n",
       "      <td>-2.463948e-02</td>\n",
       "      <td>-1.159644e-01</td>\n",
       "      <td>-1.363163e-01</td>\n",
       "      <td>-1.433386e-01</td>\n",
       "      <td>3.916958e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.278547e-01</td>\n",
       "      <td>-9.413357e-02</td>\n",
       "      <td>-2.739382e-01</td>\n",
       "      <td>-1.822219e-01</td>\n",
       "      <td>-2.392618e-01</td>\n",
       "      <td>-1.539228e-01</td>\n",
       "      <td>-1.162767e-01</td>\n",
       "      <td>-1.437413e-01</td>\n",
       "      <td>9.192296e-02</td>\n",
       "      <td>-3.605251e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.796381e-01</td>\n",
       "      <td>3.062359e-01</td>\n",
       "      <td>2.554142e-01</td>\n",
       "      <td>2.034369e-01</td>\n",
       "      <td>6.207645e-01</td>\n",
       "      <td>7.013813e-01</td>\n",
       "      <td>7.314117e-01</td>\n",
       "      <td>5.768750e-01</td>\n",
       "      <td>5.041835e-01</td>\n",
       "      <td>8.455790e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>5.827173e-01</td>\n",
       "      <td>5.194356e-01</td>\n",
       "      <td>9.164259e-01</td>\n",
       "      <td>6.362857e-01</td>\n",
       "      <td>4.952234e-01</td>\n",
       "      <td>5.328081e-01</td>\n",
       "      <td>3.446315e-01</td>\n",
       "      <td>2.370264e-01</td>\n",
       "      <td>6.933081e-01</td>\n",
       "      <td>4.835256e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.319450e+00</td>\n",
       "      <td>7.589229e+00</td>\n",
       "      <td>6.807123e+00</td>\n",
       "      <td>8.246590e+00</td>\n",
       "      <td>4.069621e+00</td>\n",
       "      <td>3.534019e+00</td>\n",
       "      <td>3.115412e+00</td>\n",
       "      <td>3.270229e+00</td>\n",
       "      <td>3.694464e+00</td>\n",
       "      <td>1.579712e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.423632e+00</td>\n",
       "      <td>4.498983e+00</td>\n",
       "      <td>2.092184e+00</td>\n",
       "      <td>3.545508e+00</td>\n",
       "      <td>4.734120e+00</td>\n",
       "      <td>6.077694e+00</td>\n",
       "      <td>1.206693e+01</td>\n",
       "      <td>1.482802e+01</td>\n",
       "      <td>2.598517e+00</td>\n",
       "      <td>3.394155e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows √ó 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            MUperGy         MUmax         MUstd         MUiqr           AAV  \\\n",
       "count  3.090000e+02  3.090000e+02  3.090000e+02  3.090000e+02  3.090000e+02   \n",
       "mean   2.184517e-16 -9.341682e-17 -2.012055e-16 -7.185910e-17 -2.299491e-16   \n",
       "std    1.001622e+00  1.001622e+00  1.001622e+00  1.001622e+00  1.001622e+00   \n",
       "min   -2.896033e+00 -9.007779e-01 -9.811186e-01 -9.062054e-01 -2.605130e+00   \n",
       "25%   -6.506351e-01 -6.155379e-01 -6.331584e-01 -5.665571e-01 -6.611972e-01   \n",
       "50%    7.134193e-02 -3.821247e-01 -2.785735e-01 -3.094307e-01 -6.571037e-02   \n",
       "75%    5.796381e-01  3.062359e-01  2.554142e-01  2.034369e-01  6.207645e-01   \n",
       "max    4.319450e+00  7.589229e+00  6.807123e+00  8.246590e+00  4.069621e+00   \n",
       "\n",
       "             AAVmin        AAVmax        AAVstd        AAViqr           LSV  \\\n",
       "count  3.090000e+02  3.090000e+02  3.090000e+02  3.090000e+02  3.090000e+02   \n",
       "mean  -4.598982e-17 -3.794160e-16  2.012055e-16  1.149746e-16  2.230506e-15   \n",
       "std    1.001622e+00  1.001622e+00  1.001622e+00  1.001622e+00  1.001622e+00   \n",
       "min   -2.493933e+00 -2.793264e+00 -1.962361e+00 -1.692180e+00 -4.227638e+00   \n",
       "25%   -7.262604e-01 -7.476646e-01 -7.570348e-01 -7.360150e-01 -6.834335e-01   \n",
       "50%   -2.463948e-02 -1.159644e-01 -1.363163e-01 -1.433386e-01  3.916958e-02   \n",
       "75%    7.013813e-01  7.314117e-01  5.768750e-01  5.041835e-01  8.455790e-01   \n",
       "max    3.534019e+00  3.115412e+00  3.270229e+00  3.694464e+00  1.579712e+00   \n",
       "\n",
       "       ...         EMstd         EMiqr         MIt02            BI  \\\n",
       "count  ...  3.090000e+02  3.090000e+02  3.090000e+02  3.090000e+02   \n",
       "mean   ... -2.299491e-17 -1.609644e-16 -5.173855e-16  2.069542e-16   \n",
       "std    ...  1.001622e+00  1.001622e+00  1.001622e+00  1.001622e+00   \n",
       "min    ... -1.911521e+00 -1.704696e+00 -1.926156e+00 -1.820530e+00   \n",
       "25%    ... -6.476983e-01 -7.664314e-01 -8.200404e-01 -7.337534e-01   \n",
       "50%    ... -1.278547e-01 -9.413357e-02 -2.739382e-01 -1.822219e-01   \n",
       "75%    ...  5.827173e-01  5.194356e-01  9.164259e-01  6.362857e-01   \n",
       "max    ...  3.423632e+00  4.498983e+00  2.092184e+00  3.545508e+00   \n",
       "\n",
       "              BImin         BImax         BIstd         BIiqr            BM  \\\n",
       "count  3.090000e+02  3.090000e+02  3.090000e+02  3.090000e+02  3.090000e+02   \n",
       "mean  -3.104313e-16 -5.403804e-16  1.897080e-16 -2.471953e-16  2.299491e-17   \n",
       "std    1.001622e+00  1.001622e+00  1.001622e+00  1.001622e+00  1.001622e+00   \n",
       "min   -1.404660e+00 -1.739618e+00 -1.504247e+00 -9.955593e-01 -3.974558e+00   \n",
       "25%   -7.380765e-01 -7.256489e-01 -5.434622e-01 -4.022145e-01 -6.025596e-01   \n",
       "50%   -2.392618e-01 -1.539228e-01 -1.162767e-01 -1.437413e-01  9.192296e-02   \n",
       "75%    4.952234e-01  5.328081e-01  3.446315e-01  2.370264e-01  6.933081e-01   \n",
       "max    4.734120e+00  6.077694e+00  1.206693e+01  1.482802e+01  2.598517e+00   \n",
       "\n",
       "              BAmin  \n",
       "count  3.090000e+02  \n",
       "mean   1.839593e-16  \n",
       "std    1.001622e+00  \n",
       "min   -1.307684e+00  \n",
       "25%   -7.269936e-01  \n",
       "50%   -3.605251e-01  \n",
       "75%    4.835256e-01  \n",
       "max    3.394155e+00  \n",
       "\n",
       "[8 rows x 61 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardisation\n",
    "scaler_std = StandardScaler()\n",
    "\n",
    "# Normalisation calcul√©e et appliqu√©e sur les donn√©es d'entrainement r√©-√©chantillonn√©es\n",
    "X_train_res_std = scaler_std.fit_transform(X_train_res) \n",
    "\n",
    "# La normalisation est ensuite appliqu√©e sur les donn√©es test avec la moyenne et l'√©cart type calcul√©s sur les donn√©es d'entrainement : \n",
    "# les donn√©es test ne sont pas r√©-√©chantillonn√©es (donn√©es vie r√©elle) mais on les appelle quand m√™me \"_res\" car elles sont normalis√©es par rapport aux donn√©es d'entrainement r√©√©chantillonn√©es\n",
    "X_test_res_std = scaler_std.transform(X_test)\n",
    "\n",
    "# Conversion en DataFrame\n",
    "X_train_res_std = pd.DataFrame(X_train_res_std, columns=z.columns)\n",
    "X_test_res_std = pd.DataFrame(X_test_res_std, columns=z.columns)\n",
    "\n",
    "# V√©rification\n",
    "X_train_res_std.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf37efaf-7749-447b-8c90-263a23a7d7fb",
   "metadata": {},
   "source": [
    "<font size = 5>üîç</font> On peut v√©rifier rapidement ci-dessus que les moyennes des variables sont autour de z√©ro et les √©cart-types autour de 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053fb98c-ae0f-4f1c-b978-0bc44f217e1a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Application </b> Impact de la standardisation sur les performances de divers algorithmes </div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b2143c33-3d34-4c17-9943-3a6ef3cd291d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f8a500aafdb4f0bae363a9a966be6c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Mod√®le :', index=4, options=('Support Vector Machine (SVC)', 'K plus proches voisins (KN‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f96fd4bc84b49ffbffab2dbb5a065c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description=\"Lancer l'analyse\", style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9626867a691f47d5b9b68e593d6e7c28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# D√©finition des mod√®les disponibles\n",
    "models = {\n",
    "    \"Support Vector Machine (SVC)\": SVC(gamma='auto', probability=True, random_state=2025),\n",
    "    \"K plus proches voisins (KNN)\": KNeighborsClassifier(n_neighbors=8),\n",
    "    \"For√™t Al√©atoire (RF)\": RandomForestClassifier(random_state=2025),\n",
    "    \"R√©gression Logistique (LR)\": LogisticRegression(solver='saga', max_iter=10000),\n",
    "    \"R√©seau de Neurones (MLP)\": MLPClassifier(max_iter=400, random_state=2025)\n",
    "}\n",
    "\n",
    "# Cr√©ation d'un menu d√©roulant pour choisir l'algorithme\n",
    "model_selector = widgets.Dropdown(\n",
    "    options=list(models.keys()),\n",
    "    value=\"R√©seau de Neurones (MLP)\",\n",
    "    description=\"Mod√®le :\",\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Bouton pour ex√©cuter l'analyse\n",
    "run_button = widgets.Button(description=\"Lancer l'analyse\", button_style='success')\n",
    "\n",
    "# Zone d'affichage des r√©sultats\n",
    "output = widgets.Output()\n",
    "\n",
    "# Fonction d'ex√©cution du test\n",
    "def run_evaluation(change):\n",
    "    with output:\n",
    "        output.clear_output()  # Nettoyer la sortie pr√©c√©dente\n",
    "        print(\"Ex√©cution en cours...\")\n",
    "        \n",
    "        model = models[model_selector.value]  # S√©lection du mod√®le choisi\n",
    "        Y = Y_train_res  # Donn√©es cibles\n",
    "\n",
    "        # √âvaluation sans normalisation\n",
    "        X = X_train_res\n",
    "        X_test_temp = X_test\n",
    "        clf = model.fit(X, Y.Echec)\n",
    "        y_scores_non_norm = model.predict_proba(X_test_temp)[:, 1]\n",
    "        fpr_non_norm, tpr_non_norm, _ = roc_curve(Y_test.Echec, y_scores_non_norm)\n",
    "        auroc_non_norm = np.round(roc_auc_score(Y_test.Echec, y_scores_non_norm), 2)\n",
    "\n",
    "        # √âvaluation avec normalisation\n",
    "        X = X_train_res_std\n",
    "        X_test_temp = X_test_res_std\n",
    "        clf = model.fit(X, Y.Echec)\n",
    "        y_scores_norm = model.predict_proba(X_test_temp)[:, 1]\n",
    "        fpr_norm, tpr_norm, _ = roc_curve(Y_test.Echec, y_scores_norm)\n",
    "        auroc_norm = np.round(roc_auc_score(Y_test.Echec, y_scores_norm), 2)\n",
    "\n",
    "        # Affichage des r√©sultats\n",
    "        print(f\"üìå Mod√®le s√©lectionn√© : {model_selector.value}\")\n",
    "        print(f\"üîπ AUROC avec donn√©es non normalis√©es : {auroc_non_norm}\")\n",
    "        print(f\"üîπ AUROC avec donn√©es normalis√©es : {auroc_norm}\")\n",
    "\n",
    "        # Trac√© des courbes ROC\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr_non_norm, tpr_non_norm, linestyle='--', label=f'Variables non standardis√©es (AUROC={auroc_non_norm})', color='blue')\n",
    "        plt.plot(fpr_norm, tpr_norm, linestyle='-', label=f'Variables standardis√©es (AUROC={auroc_norm})', color='red')\n",
    "        plt.plot([0, 1], [0, 1], linestyle='dotted', color='black', label=\"Random Guess\")\n",
    "        plt.xlabel(\"Taux de faux positifs (FPR)\")\n",
    "        plt.ylabel(\"Taux de vrais positifs (TPR)\")\n",
    "        plt.title(f\"Courbes ROC pour {model_selector.value}\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "# Lier la fonction au bouton\n",
    "run_button.on_click(run_evaluation)\n",
    "\n",
    "# Affichage des widgets\n",
    "display(model_selector, run_button, output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be81b6c-3873-4877-a75d-eb3887a2aa20",
   "metadata": {},
   "source": [
    "<font size = 5>‚ÑπÔ∏è</font>   \n",
    "Les algorithmes bas√©s sur des **arbres de d√©cisions** (comme la for√™t al√©atoire ou le gradient boosting) ne sont pas sensibles √† la standardisation des donn√©es car ils utilisent des r√®gles de d√©cisions bas√©s sur des seuils et non sur des mesures de distance. La multiplication ou la division par une constante n'affecte pas les seuils car les relations d'ordre entre les valeurs restent les m√™mes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b3b964-225a-4091-9399-99f09a7bde63",
   "metadata": {},
   "source": [
    "## üîπ4.6. S√©lection des variables  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8b0d73-756e-4837-ad6f-00b180a7b8cd",
   "metadata": {},
   "source": [
    "<img src=\"https://www.appliedaicourse.com/blog/wp-content/uploads/2024/09/feature-selection-in-machine-learning-scaled.jpg\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b73e418-728c-484a-86ff-be9b054baf3f",
   "metadata": {},
   "source": [
    "<font size=\"4\"> üöÄ **Objectif** : **r√©duire le nombre de variables** utilis√©es par un mod√®le </font>\n",
    "\n",
    "<font size=\"4\"> üîç <span style=\"color:#1114b5\">**Pourquoi est-ce utile ?**  </span> </font>\n",
    "\n",
    "‚úî **Am√©lioration des performances**  \n",
    "‚û° Moins de bruit = mod√®le plus pr√©cis et moins sujet au sur-ajustement (*overfitting*).  \n",
    "\n",
    "‚úî **R√©duction du temps de calcul**  \n",
    "‚û° Moins de variables = **entra√Ænement plus rapide** et mod√®les plus efficaces.  \n",
    "\n",
    "‚úî **Meilleure interpr√©tabilit√©**  \n",
    "‚û° Facilite l‚Äôanalyse et la compr√©hension des r√©sultats.  \n",
    "\n",
    "‚úî **√âlimination des variables inutiles ou redondantes**  \n",
    "‚û° Certaines variables n‚Äôapportent **aucune information** ou sont **fortement corr√©l√©es**.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48df564b-6592-465c-b00d-9db4f08fc194",
   "metadata": {},
   "source": [
    "Nous allons tester **quatre approches** :  \n",
    "1. Information mutuelle  \n",
    "2. √âlimination r√©cursive des variables (RFE)\n",
    "3. Analyse des composantes principales (PCA)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4n9v_KMd8JSG",
   "metadata": {
    "id": "4n9v_KMd8JSG"
   },
   "source": [
    "### ‚õìÔ∏è Information mutuelle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0F3NCkuo8ysX",
   "metadata": {
    "id": "0F3NCkuo8ysX"
   },
   "source": [
    "Fonction scikit :  `SelectKBest(score_func=mutual_info_classif)`\n",
    "\n",
    "L'**information mutuelle** est un indicateur permettant de mesurer **l‚Äôinfluence d‚Äôune variable explicative sur une variable cible**.  \n",
    "Elle provient de la **th√©orie de l'information** et quantifie **l‚Äôinformation partag√©e** entre deux variables.\n",
    "\n",
    "<font size=\"5\"> **üîç Principe** </font>    \n",
    "\n",
    "\n",
    "L‚Äôinformation mutuelle √©value **dans quelle mesure conna√Ætre une variable r√©duit l‚Äôincertitude sur une autre** :  \n",
    "\n",
    "- **Valeur √©lev√©e** ‚Üí La variable explicative contient beaucoup d‚Äôinformations sur la cible (**forte d√©pendance**).  \n",
    "- **Valeur faible** ‚Üí La variable explicative apporte peu d‚Äôinformations sur la cible.  \n",
    "- **Valeur nulle** ‚Üí Les deux variables sont totalement ind√©pendantes.  \n",
    "\n",
    "‚úî **D√©tecte les relations non lin√©aires** entre les variables  \n",
    "‚úî Fonctionne pour **variables continues et binaires**  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca541016-7bc1-4cbc-bec4-eb0108897da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S√©lection des meilleures variables explicatives en fonction de l'information mutuelle\n",
    "# `k='all'` signifie que toutes les variables sont √©valu√©es\n",
    "fs = SelectKBest(score_func=mutual_info_classif, k='all') # fs pour \"feature selection\"\n",
    "\n",
    "# Ajustement de la m√©thode sur les donn√©es d'entra√Ænement\n",
    "fs.fit(X_train_res_std, Y_train_res.Echec)\n",
    "\n",
    "# Transformation des donn√©es d'entra√Ænement et de test en ne conservant que les scores des variables s√©lectionn√©es (toutes si on a choisi k=all pr√©c√©demment)\n",
    "X_train_fs = fs.transform(X_train_res_std)\n",
    "X_test_fs = fs.transform(X_test_res_std)\n",
    "\n",
    "\n",
    "# Visualisation des scores des variables sous forme de diagramme en barres\n",
    "plt.figure(figsize=(10, 5))  # Ajustement de la taille du graphique\n",
    "plt.bar(range(len(fs.scores_)), fs.scores_)  # Affichage des scores sous forme de barres\n",
    "plt.xticks(range(len(fs.scores_)), z.columns, rotation=90)  # Rotation des √©tiquettes pour une meilleure lisibilit√©\n",
    "plt.title(\"Scores d'importance des variables (Information Mutuelle)\")\n",
    "plt.xlabel(\"Variables\")\n",
    "plt.ylabel(\"Score d'importance\")\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)  # Ajout d'une grille pour une meilleure lisibilit√©\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a055dc93-432b-485f-aba6-b479f8bc3e53",
   "metadata": {},
   "source": [
    "<font size=\"5\"> **üéØ Comment choisir k, le nombre optimal de variables √† s√©lectionner ?** </font>  \n",
    "\n",
    "Le param√®tre **k** dans `SelectKBest()` d√©termine le nombre de variables explicatives √† conserver.  \n",
    "Un bon choix de **k** est crucial pour optimiser la **pr√©cision du mod√®le** et son **efficacit√©**.  \n",
    "\n",
    "---\n",
    "\n",
    "‚û° <span style=\"color:#1114b5\">**Pourquoi est-il important de bien choisir k ?**</span>\n",
    "\n",
    "\n",
    "‚úî **Trop de variables** ‚ûù Bruit inutile, complexit√© accrue, risque de sur-ajustement (*overfitting*).  \n",
    "‚úî **Trop peu de variables** ‚ûù Perte d‚Äôinformations utiles, mod√®le sous-performant (*underfitting*).  \n",
    "üëâ **L'objectif est de trouver un √©quilibre** entre richesse de l‚Äôinformation et simplicit√© du mod√®le.\n",
    "\n",
    "\n",
    " **Solution : √âvaluer les performances du mod√®le en fonction de k.**  \n",
    "\n",
    "---\n",
    "\n",
    "‚û° <span style=\"color:#1114b5\">**Utilisation de la **Cross-Validation** pour choisir k** </span> \n",
    "\n",
    "La **Cross-Validation (CV)** permet de tester les performances d‚Äôun mod√®le tout en √©vitant le biais d‚Äôun seul √©chantillon d‚Äô√©valuation.  \n",
    "\n",
    "Principe de la Cross-Validation : \n",
    "1. On divise les **donn√©es d'entra√Ænement** en **k sous-ensembles** (*folds*).  \n",
    "2. On entra√Æne le mod√®le sur **k-1 folds** et on teste sur le fold restant.  \n",
    "3. On r√©p√®te le processus jusqu'√† ce que chaque fold ait servi √† l'√©valuation.  \n",
    "4. Les performances sont **moyenn√©es** pour obtenir une estimation fiable.  \n",
    "\n",
    "**Avantages**  \n",
    "‚úî Permet d'√©valuer **objectivement** les performances pour diff√©rents nombres de variables, **sans utiliser le jeu de test**.  \n",
    "‚úî **R√©duit l‚Äôinfluence du hasard**, contrairement √† une simple division entra√Ænement/test.  \n",
    "\n",
    "<img src=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "‚û° <span style=\"color:#1114b5\"> **Recherche du meilleur k avec Grid Search**  </span>\n",
    "\n",
    "Plut√¥t que de tester manuellement diff√©rentes valeurs de **k**, on peut automatiser le processus avec une **recherche sur grille** (*Grid Search*).  \n",
    "\n",
    "**Processus**  \n",
    "- On **teste plusieurs valeurs de k** (ex: de 5 √† 50 variables).  \n",
    "- Pour chaque valeur de **k**, on applique une **Cross-Validation** pour √©valuer les performances du mod√®le.  \n",
    "- On s√©lectionne le **k optimal**, celui qui maximise la performance sans sur-ajustement.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cddae1-4a95-4dfb-8c0d-5871411d0b43",
   "metadata": {},
   "source": [
    "> <font size=\"4\">üí° <span style=\"color:#e66612\"> **Pr√©cision technique : Utilisation des Pipelines**  </span> </font>\n",
    "> \n",
    "> Un `Pipeline` dans scikit-learn permet d‚Äôencha√Æner plusieurs √©tapes du **pr√©traitement des donn√©es** et de **l‚Äôentra√Ænement du mod√®le** en une seule structure.  \n",
    "> \n",
    "> **üìå Avantages :**  \n",
    "> - ‚úÖ **Automatisation** : Encha√Æne les transformations (ex: s√©lection de variables, normalisation, entra√Ænement).  \n",
    "> - ‚úÖ **R√©duction des erreurs** : √âvite la fuite de donn√©es en appliquant chaque transformation de mani√®re coh√©rente.   \n",
    "> üîó [Documentation scikit - Pipeline](https://scikit-learn.org/stable/modules/compose.html#pipelinehttps://scikit-learn.org/stable/modules/compose.html#pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bbc2ae-fc4d-40da-ba4e-b592227b22d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time  \n",
    "# Mesure du temps d'ex√©cution de la cellule \n",
    "\n",
    "###### 1. D√©finition de la cross-validation : 3 folds, r√©p√©t√©s 3 fois, avec stratification\n",
    "# - Stratification : Assure que la r√©partition des classes est respect√©e dans chaque fold.\n",
    "# - R√©p√©tition : R√©p√®te 3 fois la validation crois√©e avec des divisions diff√©rentes des donn√©es.\n",
    "# - Objectif : R√©duire la variance des estimations et am√©liorer la robustesse du mod√®le.\n",
    "cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=3, random_state=2025)\n",
    "\n",
    "###### 2. D√©finition du mod√®le de Machine Learning\n",
    "# On choisit une r√©gression logistique comme mod√®le de base.\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "\n",
    "###### 3. S√©lection des variables avec une m√©thode de filtrage\n",
    "# - Information Mutuelle (mutual_info_classif)\n",
    "fs = SelectKBest(score_func=mutual_info_classif)\n",
    "\n",
    "###### 4. Construction du pipeline\n",
    "# - Le pipeline permet d'automatiser la s√©lection des variables avant l'entra√Ænement du mod√®le.\n",
    "pipeline = Pipeline(steps=[('selection', fs), ('lr', model)])\n",
    "\n",
    "###### 5. D√©finition de la grille de recherche pour la s√©lection des variables\n",
    "# - On teste k entre 1 et le nombre total de variables disponibles.\n",
    "grille = dict()\n",
    "grille['selection__k'] = [i + 1 for i in range(X_train_res_std.shape[1])]\n",
    "\n",
    "###### 6. Recherche du meilleur k via une validation crois√©e et Grid Search\n",
    "# - Utilisation de l'aire sous la courbe ROC (AUC) comme m√©trique d'√©valuation.\n",
    "# - La recherche est parall√©lis√©e (`n_jobs=-1` signifie que tous les processeurs sont utilis√©s).\n",
    "recherche = GridSearchCV(pipeline, grille, scoring='roc_auc', n_jobs=-1, cv=cv)\n",
    "\n",
    "###### 7. Ex√©cution de la recherche sur grille\n",
    "# - Le mod√®le est entra√Æn√© pour chaque valeur de k et √©valu√© via la validation crois√©e.\n",
    "recherche.fit(X_train_res_std, Y_train_res.Echec)\n",
    "\n",
    "###### 8. Extraction des r√©sultats\n",
    "meilleur_k = recherche.best_params_['selection__k']  # k optimal s√©lectionn√©\n",
    "meilleur_auc = recherche.best_score_  # Meilleur AUROC obtenu\n",
    "\n",
    "best_fs = SelectKBest(score_func=mutual_info_classif, k=meilleur_k)\n",
    "best_fs.fit(X_train_res_std, Y_train_res.Echec)\n",
    "selected_vars = list(X_train_res_std.columns[best_fs.get_support()])\n",
    "\n",
    "###### 9. Affichage des meilleurs r√©sultats trouv√©s\n",
    "print('Meilleur AUROC : %.1f' % meilleur_auc)\n",
    "print('Meilleurs param√®tres :', meilleur_k)\n",
    "print(f\"Variables s√©lectionn√©es : {selected_vars}\")\n",
    "\n",
    "###### 10. Visualisation des r√©sultats de la recherche\n",
    "# - On r√©cup√®re les scores moyens et leur √©cart-type pour chaque valeur de k test√©e.\n",
    "resultats = recherche.cv_results_\n",
    "moyennes = resultats['mean_test_score']\n",
    "variances = resultats['std_test_score']\n",
    "\n",
    "### Trac√© du score AUROC en fonction du nombre de variables s√©lectionn√©es (k)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.errorbar(grille['selection__k'], moyennes, yerr=variances, fmt='-o', capsize=5, label=\"AUROC moyen\")\n",
    "\n",
    "# Mise en √©vidence du k s√©lectionn√©\n",
    "plt.axvline(meilleur_k, color='red', linestyle='--', linewidth=1.5, label=f'k optimal = {meilleur_k}')\n",
    "plt.scatter(meilleur_k, meilleur_auc, color='red', s=100, edgecolors='black', label=\"Meilleur score\")\n",
    "\n",
    "# Mise en forme du graphique\n",
    "plt.title(\"S√©lection du nombre optimal de variables (k) via Grid Search\")\n",
    "plt.xlabel('Nombre de variables s√©lectionn√©es (k)')\n",
    "plt.ylabel('AUROC')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca94e004-1987-43e1-b402-d17329aec22c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Application </b> On peut r√©p√©ter la s√©lection pour diff√©rents type d'algortihmes ML et m√©triques de performance : </div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68aab0ea-fb6b-47be-95a4-ea8efba51484",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Si probl√®me dans Colab\n",
    "#from google.colab import output\n",
    "#output.enable_custom_widget_manager()\n",
    "\n",
    "# D√©finition des mod√®les disponibles\n",
    "model_options = {\n",
    "    \"R√©gression Logistique\": LogisticRegression(solver='lbfgs'),\n",
    "    \"For√™t Al√©atoire\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"SVM\": SVC(probability=True),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# D√©finition des m√©triques disponibles\n",
    "metrics_options = {\n",
    "    \"AUC-ROC\": \"roc_auc\",\n",
    "    \"Accuracy\": \"accuracy\",\n",
    "    \"F1 Score\": \"f1_weighted\",\n",
    "    \"Pr√©cision\": \"precision\",\n",
    "    \"Rappel\": \"recall\"\n",
    "}\n",
    "\n",
    "# Cr√©ation des widgets interactifs pour le mod√®le et la m√©trique\n",
    "algo_selector = widgets.Dropdown(\n",
    "    options=model_options.keys(),\n",
    "    value=\"R√©gression Logistique\",\n",
    "    description=\"Mod√®le :\"\n",
    ")\n",
    "\n",
    "metric_selector = widgets.Dropdown(\n",
    "    options=metrics_options.keys(),\n",
    "    value=\"AUC-ROC\",\n",
    "    description=\"M√©trique :\"\n",
    ")\n",
    "\n",
    "# Bouton pour ex√©cuter le calcul\n",
    "run_button = widgets.Button(\n",
    "    description=\"Lancer le calcul\",\n",
    "    button_style='success',\n",
    "    tooltip=\"Cliquez pour ex√©cuter la recherche du k optimal\"\n",
    ")\n",
    "\n",
    "# Zone de sortie pour afficher les r√©sultats\n",
    "output = widgets.Output()\n",
    "\n",
    "def run_grid_search(b):\n",
    "    \"\"\" Fonction ex√©cut√©e lorsqu'on clique sur le bouton \"\"\"\n",
    "    \n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        print(\"Ex√©cution en cours...\")\n",
    "\n",
    "        # S√©lection du mod√®le et de la m√©trique\n",
    "        model_name = algo_selector.value\n",
    "        metric_name = metric_selector.value\n",
    "\n",
    "        model = model_options[model_name]\n",
    "        metric = metrics_options[metric_name]\n",
    "\n",
    "        # Validation crois√©e fix√©e √† 3 folds et 3 r√©p√©titions\n",
    "        cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=3, random_state=2025)\n",
    "\n",
    "        # S√©lection des variables avec Information Mutuelle\n",
    "        fs = SelectKBest(score_func=mutual_info_classif)\n",
    "\n",
    "        # Cr√©ation du pipeline (s√©lection des variables + mod√®le)\n",
    "        pipeline = Pipeline(steps=[('selection', fs), ('model', model)])\n",
    "\n",
    "        # D√©finition de la grille de recherche pour k\n",
    "        grille = {'selection__k': [i + 1 for i in range(X_train_res_std.shape[1])]}\n",
    "\n",
    "        # Recherche du meilleur k via Grid Search\n",
    "        recherche = GridSearchCV(pipeline, grille, scoring=metric, n_jobs=-1, cv=cv)\n",
    "        recherche.fit(X_train_res_std, Y_train_res.Echec)\n",
    "\n",
    "        # Extraction des r√©sultats\n",
    "        meilleur_k = recherche.best_params_['selection__k']\n",
    "        meilleur_score = recherche.best_score_\n",
    "\n",
    "        # R√©cup√©ration des indices des variables s√©lectionn√©es\n",
    "        best_fs = SelectKBest(score_func=mutual_info_classif, k=meilleur_k)\n",
    "        best_fs.fit(X_train_res_std, Y_train_res.Echec)\n",
    "        selected_vars = list(X_train_res_std.columns[best_fs.get_support()])\n",
    "\n",
    "        # Affichage des r√©sultats\n",
    "        print(f\"\\nMeilleur {metric_name} : {meilleur_score:.3f}\")\n",
    "        print(f\"Meilleur nombre de variables s√©lectionn√©es (k) : {meilleur_k}\")\n",
    "        print(f\"Variables s√©lectionn√©es : {selected_vars}\")\n",
    "        \n",
    "        # R√©cup√©ration des scores pour chaque valeur de k test√©e\n",
    "        resultats = recherche.cv_results_\n",
    "        moyennes = resultats['mean_test_score']\n",
    "        variances = resultats['std_test_score']\n",
    "\n",
    "        # Affichage graphique des r√©sultats\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.errorbar(grille['selection__k'], moyennes, yerr=variances, fmt='-o', capsize=5, label=f\"{metric_name} moyen\")\n",
    "        \n",
    "        # Mise en √©vidence du k s√©lectionn√©\n",
    "        plt.axvline(meilleur_k, color='red', linestyle='--', linewidth=1.5, label=f'k optimal = {meilleur_k}')\n",
    "        plt.scatter(meilleur_k, meilleur_score, color='red', s=100, edgecolors='black', label=\"Meilleur score\")\n",
    "\n",
    "        # Mise en forme du graphique\n",
    "        plt.title(f\"Impact de {model_name} sur la s√©lection de k ({metric_name})\")\n",
    "        plt.xlabel(\"Nombre de variables s√©lectionn√©es (k)\")\n",
    "        plt.ylabel(metric_name)\n",
    "        plt.legend()\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.show()\n",
    "\n",
    "# Associer la fonction au bouton\n",
    "run_button.on_click(run_grid_search)\n",
    "\n",
    "# Affichage de l'interface\n",
    "display(algo_selector, metric_selector, run_button, output)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92411fc-98f6-462f-bc57-7f94bd12243d",
   "metadata": {
    "id": "71360c16"
   },
   "source": [
    "### üîÅ M√©thode de s√©lection r√©cursive (RFE)\n",
    "üìå **Utilis√©e pour s√©lectionner un sous-ensemble optimal de variables**  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16745625-5181-4556-bc62-5051e6b71b32",
   "metadata": {},
   "source": [
    "<img src=\"https://www.blog.trainindata.com/wp-content/uploads/2022/08/rfesklearn.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f41f2bb-1fe0-4e2e-89d4-33ce09110f2a",
   "metadata": {},
   "source": [
    "L'**Elimination R√©cursive des Variables (RFE)** est une technique de **s√©lection de variables** qui fonctionne de mani√®re it√©rative pour identifier les variables les plus pertinentes.\n",
    "\n",
    "<font size=\"5\"> **üîç Principe** </font> \n",
    "1. **Entra√Ænement du mod√®le** avec toutes les variables.\n",
    "2. **√âvaluation de l'importance** des variables (ex: coefficients d'une r√©gression ou importance des features d'un arbre).\n",
    "3. **Suppression** de la variable la moins importante.\n",
    "4. **R√©p√©tition du processus** jusqu'√† atteindre un nombre d√©fini de variables.\n",
    "5. **Conservation des variables les plus significatives**.\n",
    "\n",
    "‚úî Adapt√© aux **mod√®les lin√©aires** et **arbres de d√©cision**  \n",
    "‚úî Peut √™tre combin√© avec une **validation crois√©e (RFECV)** pour d√©terminer automatiquement le nombre optimal de variables  \n",
    "‚úî Permet de **r√©duire le sur-ajustement** en limitant le nombre de variables inutiles  \n",
    "\n",
    "üîó **Scikit-learn :** `sklearn.feature_selection.RFE` et `RFECV` pour la version avec validation crois√©e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381f37a9-bd5d-4842-9f93-80296e7d79da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# Mesure du temps d'ex√©cution de la cellule (utile pour √©valuer les performances du code)\n",
    "\n",
    "# Cr√©ation d'un pipeline pour normaliser les donn√©es et entra√Æner le mod√®le\n",
    "# - Normalisation avec StandardScaler (moyenne = 0, √©cart-type = 1)\n",
    "# - Mod√®le utilis√© : R√©gression Logistique\n",
    "pipeline = Pipeline([\n",
    "    ('scale', StandardScaler()),  \n",
    "    ('clf', LogisticRegression(solver='lbfgs'))  \n",
    "])\n",
    "\n",
    "# D√©finition de la validation crois√©e\n",
    "# - 3 folds (d√©coupage des donn√©es en 3 groupes)\n",
    "# - R√©p√©t√© 3 fois pour am√©liorer la robustesse de la s√©lection de variables\n",
    "kfold = RepeatedStratifiedKFold(n_splits=3, n_repeats=3, random_state=2025)\n",
    "\n",
    "# D√©finition du processus d'√©limination r√©cursive des variables (RFE avec CV)\n",
    "rfecv_LR = RFECV(\n",
    "    estimator=pipeline,  \n",
    "    step=1,  # Suppression de 1 variable √† chaque it√©ration\n",
    "    cv=kfold,  \n",
    "    scoring='roc_auc',  # Utilisation de l'AUC-ROC comme m√©trique d'√©valuation\n",
    "    min_features_to_select=1,  # Nombre minimal de variables √† conserver\n",
    "    importance_getter=\"named_steps.clf.coef_\"  \n",
    ")\n",
    "\n",
    "# Entra√Ænement du processus RFE avec CV sur les donn√©es non standardis√©s (car la standardisation est int√©gr√©e dans le pipeline)\n",
    "rfecv_LR.fit(X_train_res, Y_train_res.Echec)\n",
    "\n",
    "# Extraction des r√©sultats de la s√©lection de variables\n",
    "mask = rfecv_LR.support_  # Masque bool√©en des variables s√©lectionn√©es\n",
    "X_train_rfe = X_train_res.loc[:, mask]  # S√©lection des variables dans X_train\n",
    "X_test_rfe = X_test.loc[:, mask]  # S√©lection des variables dans X_test\n",
    "\n",
    "# Affichage des r√©sultats\n",
    "print(\"Nombre de variables s√©lectionn√©es par le processus RFE :\", rfecv_LR.n_features_)\n",
    "print(\"Variables s√©lectionn√©es :\", list(X_train_rfe.columns))\n",
    "\n",
    "# R√©cup√©ration des scores de la validation crois√©e pour chaque sous-ensemble de variables\n",
    "x = range(1, len(mask) + 1)  # Nombre total de variables test√©es\n",
    "y = rfecv_LR.cv_results_['mean_test_score']  # Score moyen AUC-ROC pour chaque k\n",
    "error = rfecv_LR.cv_results_['std_test_score']  # √âcart-type des scores\n",
    "\n",
    "# Affichage des r√©sultats sous forme de graphique\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(x, y, marker='o', linestyle='-')\n",
    "plt.fill_between(x, y-error, y+error, alpha=0.2)  # Ajout d'une bande d'erreur\n",
    "plt.axvline(rfecv_LR.n_features_, color='red', linestyle='--', linewidth=1.5, label=f'k optimal = {rfecv_LR.n_features_}')  \n",
    "plt.xlabel(\"Nombre de variables s√©lectionn√©es\")\n",
    "plt.ylabel(\"AUROC sur la CV\")\n",
    "plt.title(\"S√©lection RFE bas√©e sur la R√©gression Logistique\")\n",
    "plt.ylim(0.5, 1.0)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d668edf1-89f6-4cd9-bbf8-e2204a71a063",
   "metadata": {},
   "source": [
    "<font size=\"8\"> ‚ö†Ô∏è </font>\n",
    "><span style=\"color:#1114b5\"> **Standardisation et cross-validation** </span>  \n",
    "Dans ce code, **nous n'utilisons pas le jeu d'entrainement pr√©alablement standardis√©** dans la CV qui sert pour ajuster `RFECV`.  \n",
    "En effet, la standardisation est **int√©gr√©e dans le pipeline**, ce qui permet de garantir une s√©paration stricte entre les donn√©es d'entra√Ænement et les donn√©es de validation.\n",
    ">\n",
    "> <span style=\"color:#1114b5\"> **Pourquoi est-ce important ?**   </span>   \n",
    "Lors de la **validation crois√©e**, les donn√©es d'entra√Ænement et de validation changent √† chaque it√©ration.  \n",
    "Si nous standardisions l'ensemble des donn√©es avant la validation crois√©e, la moyenne et l'√©cart-type utilis√©s pour la transformation incluraient des informations provenant des folds de validation.  \n",
    "Cela entra√Ænerait une **fuite de donn√©es**, biaisant ainsi l'√©valuation du mod√®le.\n",
    ">\n",
    "> <span style=\"color:#1114b5\"> **Avantage de l'int√©gration dans le pipeline**   </span>   \n",
    "En int√©grant `StandardScaler()` dans le pipeline, chaque fold de validation est **normalis√© uniquement** avec les statistiques (moyenne et √©cart-type) calcul√©es sur les folds d'entra√Ænement de l'it√©ration correspondante.  \n",
    "Cela garantit une **ind√©pendance stricte** entre les folds d'entra√Ænement et les folds de validation, assurant une √©valuation plus r√©aliste des performances du mod√®le.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdff2b34-e4ee-4a3f-ae56-fd54f2e157ec",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Application </b> On peut r√©p√©ter la s√©lection pour diff√©rents type d'algortihmes et diff√©rentes m√©triques de performance : </div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31b36d7-9d53-44f8-a6b3-2be6273f986c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des algorithmes disponibles\n",
    "algorithms = {\n",
    "    \"R√©gression Logistique\": LogisticRegression(solver='lbfgs'),\n",
    "    \"For√™t Al√©atoire\": RandomForestClassifier(),\n",
    "    \"SVM\": SVC(kernel=\"linear\", probability=True),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier()\n",
    "}\n",
    "\n",
    "# Liste des m√©triques de scoring disponibles\n",
    "scoring_metrics = {\n",
    "    \"AUC-ROC\": \"roc_auc\",\n",
    "    \"Accuracy\": \"accuracy\",\n",
    "    \"F1-Score\": \"f1_weighted\",\n",
    "    \"Pr√©cision\": \"precision\",\n",
    "    \"Recall\": \"recall\"\n",
    "}\n",
    "\n",
    "# Widgets interactifs\n",
    "algo_selector = widgets.Dropdown(\n",
    "    options=algorithms.keys(),\n",
    "    value=\"R√©gression Logistique\",\n",
    "    description=\"Algorithme:\"\n",
    ")\n",
    "\n",
    "metric_selector = widgets.Dropdown(\n",
    "    options=scoring_metrics.keys(),\n",
    "    value=\"AUC-ROC\",\n",
    "    description=\"M√©trique:\"\n",
    ")\n",
    "\n",
    "run_button = widgets.Button(description=\"Lancer le calcul\", button_style='success')\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "# Fonction ex√©cut√©e au clic du bouton\n",
    "def run_rfecv(_):\n",
    "    with output:\n",
    "        output.clear_output(wait=True)\n",
    "        print(\"Ex√©cution en cours...\")\n",
    "\n",
    "        # S√©lection de l'algorithme et de la m√©trique en fonction des choix utilisateur\n",
    "        selected_algo = algorithms[algo_selector.value]\n",
    "        selected_metric = scoring_metrics[metric_selector.value]\n",
    "\n",
    "        # Cr√©ation du pipeline avec normalisation et mod√®le s√©lectionn√©\n",
    "        pipeline = Pipeline([\n",
    "            ('scale', StandardScaler()),  \n",
    "            ('clf', selected_algo)\n",
    "        ])\n",
    "\n",
    "        # Param√©trage de la validation crois√©e (3 folds, 3 r√©p√©titions)\n",
    "        kfold = RepeatedStratifiedKFold(n_splits=3, n_repeats=3, random_state=2025)\n",
    "\n",
    "        # Processus de s√©lection des variables (RFE avec validation crois√©e)\n",
    "        rfecv = RFECV(\n",
    "            estimator=pipeline,  \n",
    "            step=1,  \n",
    "            cv=kfold,  \n",
    "            scoring=selected_metric,  \n",
    "            min_features_to_select=1,  \n",
    "            importance_getter=\"named_steps.clf.coef_\" if isinstance(selected_algo, LogisticRegression) or isinstance(selected_algo, SVC) else \"named_steps.clf.feature_importances_\"  \n",
    "        )\n",
    "\n",
    "        # Entra√Ænement du processus RFE avec CV sur les donn√©es (les donn√©es ne sont pas standardis√©es avant car le pipeline s'en charge)\n",
    "        rfecv.fit(X_train_res, Y_train_res.Echec)\n",
    "\n",
    "        # R√©cup√©ration des variables s√©lectionn√©es\n",
    "        mask = rfecv.support_\n",
    "        X_train_rfe = X_train_res.loc[:, mask]\n",
    "        X_test_rfe = X_test.loc[:, mask]\n",
    "\n",
    "        print(\"Nombre de variables s√©lectionn√©es :\", rfecv.n_features_)\n",
    "        print(\"Variables s√©lectionn√©es :\", list(X_train_rfe.columns))\n",
    "\n",
    "        # R√©cup√©ration des scores de la validation crois√©e pour chaque sous-ensemble de variables\n",
    "        x = range(1, len(mask) + 1)  \n",
    "        y = rfecv.cv_results_['mean_test_score']  \n",
    "        error = rfecv.cv_results_['std_test_score']\n",
    "\n",
    "        # Affichage du graphique\n",
    "        plt.figure(figsize=(8,5))\n",
    "        plt.plot(x, y, marker='o', linestyle='-')\n",
    "        plt.fill_between(x, y-error, y+error, alpha=0.2)\n",
    "        plt.axvline(rfecv.n_features_, color='red', linestyle='--', linewidth=1.5, label=f'k optimal = {rfecv.n_features_}')  \n",
    "        plt.xlabel(\"Nombre de variables s√©lectionn√©es\")\n",
    "        plt.ylabel(selected_metric)\n",
    "        plt.title(f\"S√©lection RFE bas√©e sur {algo_selector.value}\")\n",
    "        plt.ylim(0.3, 1.0)\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        \n",
    "        # Effacer le message d'ex√©cution en cours\n",
    "        clear_output(wait=True)\n",
    "\n",
    "# Associer l'action au clic du bouton\n",
    "run_button.on_click(run_rfecv)\n",
    "\n",
    "# Affichage des widgets interactifs\n",
    "display(algo_selector, metric_selector, run_button, output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2IHoVe1x6kc6",
   "metadata": {
    "id": "2IHoVe1x6kc6"
   },
   "source": [
    "### üìâ M√©thode de r√©duction de dimension (PCA)\n",
    "\n",
    "- La PCA (Principal Composant Analysis) permet de **transformer** ces variables en un **nouveau jeu de variables non corr√©l√©es** appel√©es **composantes principales**.\n",
    "- Elle permet de **r√©duire la dimension** des donn√©es tout en gardant **l‚Äôessentiel de la variabilit√©**.\n",
    "\n",
    "<font size=\"5\"> **üîç Principe** </font>    \n",
    "\n",
    "\n",
    "Objectif : projeter le jeu d'entrainement sur un hyperplan de plus faible dimension en selectionnant l'hyperplan qui conserve le plus possible la variance des doon√©es pour perdre le moins d'information.  \n",
    "1. **Normalisation des donn√©es**  \n",
    "   - Les variables doivent √™tre **mises √† l‚Äô√©chelle** pour √©viter qu‚Äôune variable avec une grande amplitude ne domine les autres.\n",
    "\n",
    "2. **Calcul des Composantes Principales**  \n",
    "   - L‚ÄôACP trouve **les axes** qui maximisent la variance des donn√©es.\n",
    "   - Ces axes sont des **combinaisons lin√©aires** des variables initiales.\n",
    "\n",
    "3. **S√©lection des Composantes les Plus Importantes**  \n",
    "   - On **classe les composantes** selon leur **variance expliqu√©e**.\n",
    "   - On choisit g√©n√©ralement **les premi√®res composantes** qui expliquent **80-90%** de la variance totale.\n",
    "\n",
    "4. **Projection des Donn√©es**  \n",
    "   - Les donn√©es d‚Äôorigine sont projet√©es dans cet espace de dimensions r√©duites, ce qui diminue la complexit√© et le risque de sur-apprentissage.\n",
    "\n",
    "\n",
    "üîπ PCA est particuli√®rement utile lorsque les variables sont fortement corr√©l√©es. Cependant, il **modifie l‚Äôinterpr√©tabilit√© des donn√©es**, car les nouvelles variables (composantes principales) ne correspondent plus directement aux variables initiales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f47217a-1526-4275-a306-dbc52376aca6",
   "metadata": {},
   "source": [
    "<img src=\"https://iq.opengenus.org/content/images/2020/03/pca_classic.png\" alt=\"drawing\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189dfa6d-768c-4447-908e-bc2c48fd623c",
   "metadata": {},
   "source": [
    "<img src=\"https://www.simplilearn.com/ice9/free_resources_article_thumb/Variance%26Residuals.PNG\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "61fd757f-e3ff-48e8-8a71-05da1dc768aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.72496350e-01, 1.62944354e-01, 1.00551844e-01, 7.35289089e-02,\n",
       "       6.07122832e-02, 4.79127121e-02, 3.66812537e-02, 3.07149604e-02,\n",
       "       2.98601749e-02, 2.24504795e-02, 1.97161301e-02, 1.74513932e-02,\n",
       "       1.52418233e-02, 1.17618032e-02, 1.05531492e-02, 9.42790918e-03,\n",
       "       8.58002173e-03, 7.58326300e-03, 6.25337834e-03, 5.53209016e-03,\n",
       "       5.31663168e-03, 4.93437017e-03, 4.41659245e-03, 3.55379458e-03,\n",
       "       3.07282242e-03, 2.81079833e-03, 2.45445628e-03, 2.29017473e-03,\n",
       "       2.14215925e-03, 1.82675253e-03, 1.69753764e-03, 1.64038487e-03,\n",
       "       1.42494887e-03, 1.34252831e-03, 1.16858427e-03, 9.79862349e-04,\n",
       "       9.13155565e-04, 8.11817676e-04, 7.60365859e-04, 6.94327942e-04,\n",
       "       6.59774132e-04, 5.72546193e-04, 5.34346837e-04, 4.80191441e-04,\n",
       "       4.44518223e-04, 4.09628560e-04, 3.78090308e-04, 3.26589904e-04,\n",
       "       2.88053491e-04, 2.67265901e-04, 2.33609522e-04, 2.15578167e-04,\n",
       "       1.91876831e-04, 1.52705424e-04, 1.26168605e-04, 1.18798636e-04,\n",
       "       1.05853860e-04, 9.11002787e-05, 8.53591750e-05, 5.99368742e-05,\n",
       "       5.16591351e-05])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialisation de PCA sans restriction sur le nombre de composantes\n",
    "pca = PCA(random_state=2025)\n",
    "\n",
    "# Ajustement du PCA sur les donn√©es d'entra√Ænement normalis√©es et transformation des donn√©es\n",
    "X_pca = pca.fit_transform(X_train_res_std)\n",
    "\n",
    "# Affichage de la variance expliqu√©e par chaque composante principale\n",
    "pca.explained_variance_ratio_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20db1365-870e-412a-bd34-7ac3e882143e",
   "metadata": {},
   "source": [
    "<font size=\"5\"> **üìå Interpr√©tation des r√©sultats** </font>   \n",
    "\n",
    "\n",
    "\n",
    "La variable **`explained_variance_ratio_`** indique **la proportion de variance captur√©e** par chaque composante principale.\n",
    "\n",
    "Par exemple :\n",
    "- **27%** de la variance est expliqu√©e par la 1 ≥·µâ composante.\n",
    "- **16%** par la 2·µâ composante.\n",
    "- Moins de **3%** pour la 11·µâ composante ‚Üí elle apporte peu d'information.\n",
    "\n",
    "üí° Pour choisir le **nombre optimal de dimensions**, il faut s'assurer que les composantes retenues expliquent une grande partie de la variance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d270563-5bb5-4f34-a1ec-bf234b00cf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de la somme cumul√©e des contributions des composantes\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "# D√©termination du nombre de dimensions n√©cessaires pour conserver au moins 95% de la variance totale\n",
    "d = np.argmax(cumsum >= 0.95) + 1  #argmax donne l'indice du tableau de la somme cumul√©e o√π elle devient sup√©rieure ou √©gale √† 0.95. On ajoute 1 car les indices d√©butent √† 0. \n",
    "\n",
    "print(\"Nombre optimal de dimensions √† conserver :\", d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea041bf5-78de-4bde-b817-ce5027e0e7a3",
   "metadata": {},
   "source": [
    "**Explication de la s√©lection du nombre de dimensions**   \n",
    "- La somme cumul√©e **permet d'identifier combien de dimensions** sont n√©cessaires pour capturer **95% de l'information**.\n",
    "- Ici, `d` correspond au **nombre minimal de dimensions** √† conserver pour ne pas perdre trop d'information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d852566-082a-45b5-82b6-9b45bea3283b",
   "metadata": {},
   "source": [
    "<font size=\"5\"> **üìå Transformation des donn√©es** </font>   \n",
    "\n",
    "\n",
    "- En fixant **`n_components=0.95`**, PCA s√©lectionne **automatiquement** le nombre optimal de dimensions pour expliquer **95% de la variance**.\n",
    "- On applique cette transformation aux donn√©es, ce qui r√©duit leur dimension sans trop perdre d‚Äôinformation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b4e4f0-da3a-454c-a9c5-6f5a952eadc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R√©duction de dimension avec PCA en gardant 95% de la variance\n",
    "pca = PCA(n_components=0.95)\n",
    "X_reduit = pca.fit_transform(X_train_res_std)\n",
    "\n",
    "# Affichage de la nouvelle dimension des donn√©es\n",
    "X_reduit.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1475e258-a1e3-4793-a4e6-83becaf3a222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage de la courbe de variance expliqu√©e en fonction du nombre de dimensions\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(cumsum, linewidth=3, label=\"Variance expliqu√©e cumul√©e\")\n",
    "plt.axvline(d, color='red', linestyle='--', linewidth=1.5, label=f'{d} dimensions retenues')\n",
    "plt.axhline(0.95, color='black', linestyle='--', linewidth=1.2, label=\"Seuil 95%\")\n",
    "plt.xlabel(\"Nombre de dimensions\")\n",
    "plt.ylabel(\"Variance expliqu√©e\")\n",
    "plt.title(\"√âvolution de la variance expliqu√©e en fonction des dimensions\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49a1c46-af22-410f-b9a5-9e7a2d8e3419",
   "metadata": {},
   "source": [
    "<font size=\"5\"> **üìå Visualisation de la variance expliqu√©e** </font>   \n",
    "\n",
    "\n",
    "Ce graphique permet de visualiser :\n",
    "- La **courbe de variance expliqu√©e cumul√©e**.\n",
    "- La **valeur seuil des 95%** de variance retenue.\n",
    "- Le **point o√π la r√©duction de dimension est optimale** (ligne rouge).\n",
    "\n",
    "üí° **√âpaule sur la courbe** : indique un point √† partir duquel ajouter plus de dimensions apporte peu de b√©n√©fices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbc5d34-d5cf-4d9f-bc14-b5ae30ab13ba",
   "metadata": {},
   "source": [
    "**üöÄ Remarque importante**   \n",
    "L'inconv√©nient de PCA est que les nouvelles variables obtenues (composantes principales) **ne correspondent plus directement aux variables initiales**.  \n",
    "Ainsi, pour faire des **pr√©dictions sur de nouvelles donn√©es**, il faut :\n",
    "1. **Appliquer PCA** sur la totalit√© des variables initiales.\n",
    "2. **Transformer les nouvelles donn√©es** avec les m√™mes param√®tres que ceux appris sur l'entra√Ænement.\n",
    "3. **R√©aliser la pr√©diction** avec les donn√©es transform√©es.\n",
    "\n",
    "üí° Dans certains cas, **la transformation PCA peut √™tre co√ªteuse en calcul**, notamment si elle doit √™tre appliqu√©e en temps r√©el.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee47961d-6470-4258-bd69-5602492ba6c3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Application </b> Evaluer les performances de diff√©rents algo pour diff√©rents dimensions d√©finies par PCA et selon diff√©rents scores </div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4391e980-b6a5-443d-99b9-cde0931237f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=UserWarning)  # Ignore les UserWarnings\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)  # Ignore les RuntimeWarnings\n",
    "\n",
    "\n",
    "### D√©finition des options interactives pour l'utilisateur\n",
    "\n",
    "# S√©lection de l'algorithme\n",
    "algo_options = {\n",
    "    \"R√©gression Logistique\": LogisticRegression(solver='lbfgs'),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"SVM Lin√©aire\": SVC(kernel=\"linear\"),\n",
    "    \"Analyse Discriminante Quadratique\": QuadraticDiscriminantAnalysis(), \n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Multi-Layer Perceptron\": MLPClassifier()\n",
    "}\n",
    "algo_selector = widgets.Dropdown(options=algo_options, description=\"Algorithme:\")\n",
    "\n",
    "# S√©lection de la m√©trique d'√©valuation\n",
    "metric_options = {\n",
    "    \"ROC AUC\": 'roc_auc',\n",
    "    \"Balanced Accuracy\": 'balanced_accuracy',\n",
    "    \"F1 Weighted\": 'f1_weighted',\n",
    "    \"Accuracy\": 'accuracy',\n",
    "    \"Precision\": 'precision',\n",
    "    \"Recall\": 'recall'\n",
    "}\n",
    "metric_selector = widgets.Dropdown(options=metric_options, description=\"M√©trique:\")\n",
    "\n",
    "# Bouton pour lancer l'ex√©cution\n",
    "run_button = widgets.Button(description=\"Lancer le calcul\", button_style='success')\n",
    "output = widgets.Output()\n",
    "\n",
    "\n",
    "### Fonction pour ex√©cuter l'√©valuation en fonction des choix de l'utilisateur\n",
    "\n",
    "def execute_evaluation(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        print(\"Ex√©cution en cours ...\")\n",
    "\n",
    "        # D√©finition de la validation crois√©e stratifi√©e\n",
    "        cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=5, random_state=2025)\n",
    "\n",
    "        # D√©finition du pipeline avec PCA et l'algorithme s√©lectionn√©\n",
    "        pipeline = Pipeline(steps=[('selection', PCA()), ('model', algo_selector.value)])\n",
    "\n",
    "        # D√©finition de la grille de recherche pour la s√©lection du nombre de dimensions avec PCA\n",
    "        grille = {'selection__n_components': [i+1 for i in range(1, X_train_res_std.shape[1]+1)]}\n",
    "\n",
    "        # D√©finition de la recherche sur grille avec la m√©trique s√©lectionn√©e\n",
    "        recherche = GridSearchCV(pipeline, grille, scoring=metric_selector.value, n_jobs=-1, cv=cv)\n",
    "        recherche.fit(X_train_res_std, Y_train_res.Echec)\n",
    "\n",
    "        # R√©sum√© des r√©sultats\n",
    "        print(f\"Meilleur score ({metric_selector.label}) : {recherche.best_score_:.3f}\")\n",
    "        print(f\"Meilleur nombre de dimensions s√©lectionn√©es : {recherche.best_params_['selection__n_components']}\")\n",
    "\n",
    "        # R√©cup√©ration des r√©sultats d√©taill√©s\n",
    "        resultats = recherche.cv_results_\n",
    "        moyennes = resultats['mean_test_score']\n",
    "        variances = resultats['std_test_score']\n",
    "        n_components = grille['selection__n_components']\n",
    "\n",
    "        # Affichage du graphe des performances\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.errorbar(n_components, moyennes, yerr=variances, fmt='-o', capsize=5)\n",
    "        plt.axvline(recherche.best_params_['selection__n_components'], color='red', linestyle='--', label=\"Best n_components\")\n",
    "        plt.xlabel(\"Nombre de dimensions s√©lectionn√©es (PCA)\")\n",
    "        plt.ylabel(f\"Score {metric_selector.label}\")\n",
    "        plt.title(f\"Performance en fonction du nombre de dimensions ({metric_selector.label})\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "# Liaison du bouton √† la fonction d'ex√©cution\n",
    "run_button.on_click(execute_evaluation)\n",
    "\n",
    "### Affichage des widgets interactifs\n",
    "display(algo_selector, metric_selector, run_button, output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad14289-c6d9-4a93-bed0-2fd9af07708a",
   "metadata": {},
   "source": [
    "### üöß R√©sum√© des m√©thodes de s√©lection de variables \n",
    "\n",
    "La s√©lection de variables est une √©tape essentielle en **Machine Learning** pour am√©liorer la **pr√©cision** des mod√®les, r√©duire la **complexit√©** et √©viter le **sur-ajustement**. Diff√©rentes approches existent, chacune ayant ses **avantages** et **inconv√©nients** en fonction du type de donn√©es.\n",
    "\n",
    "\n",
    "\n",
    "| **M√©thode** | **Avantages** | **Inconv√©nients** | **Adapt√© √† quel type de donn√©es ?** |\n",
    "|------------|--------------|-----------------|-----------------------------|\n",
    "| **Information Mutuelle** | ‚úÖ Captures des **relations non lin√©aires**<br>‚úÖ Fonctionne avec **variables continues et cat√©gorielles** | ‚ùå Ne tient pas compte des **interactions entre variables**<br>‚ùå Moins efficace sur de **grands ensembles de donn√©es** | üîπ Donn√©es h√©t√©rog√®nes (mixtes)<br>üîπ Lorsque la relation entre les variables explicatives et la cible peut √™tre **non lin√©aire** |\n",
    "| **RFE (Recursive Feature Elimination)** | ‚úÖ S√©lection optimis√©e via un **mod√®le sous-jacent**<br>‚úÖ Garde les **variables les plus importantes** pour le mod√®le | ‚ùå **Long √† ex√©cuter** si beaucoup de variables<br>‚ùå D√©pend du **mod√®le choisi** | üîπ Convient aux mod√®les **lin√©aires et non lin√©aires**<br>üîπ Utile si on veut **garder un sous-ensemble optimal** |\n",
    "| **PCA (Analyse en Composantes Principales)** | ‚úÖ R√©duit la **multicolin√©arit√©**<br>‚úÖ Diminue la **dimension** de l'espace des variables tout en pr√©servant l'information | ‚ùå **Perte d'interpr√©tabilit√©** des variables<br>‚ùå Ne fonctionne que sur **variables continues** | üîπ Quand on a **beaucoup de variables corr√©l√©es**<br>üîπ Si l'objectif est **r√©duction de dimension et non interpr√©tation** |\n",
    "\n",
    "\n",
    "\n",
    "<font size=\"4\"> üìå **Autres m√©thodes de s√©lection de variables :**   </font>  \n",
    "\n",
    "\n",
    "En plus de **l'Information Mutuelle, RFE et PCA**, il existe d'autres techniques : üîó [Documentation Scikit - Feature selection](https://scikit-learn.org/stable/modules/feature_selection.html#feature-selection)   \n",
    "\n",
    "<font size=\"3\"> 1Ô∏è‚É£ <span style=\"color:#0a51ab\"> **M√©thodes de s√©lection univari√©es** :</span>   </font>   \n",
    "   - **ANOVA** (ANalysis of VAriance) : S√©lectionne les variables les plus corr√©l√©es avec la cible (utile pour variables continues et cibles cat√©goriques).\n",
    "        - üîπ Scikit : `sklearn.feature_selection.SelectKBest(score_func=f_classif)`   \n",
    "   - **Chi¬≤** : Test d'ind√©pendance pour variables **cat√©goriques**.\n",
    "        - üîπ Scikit : `sklearn.feature_selection.SelectKBest(score_func=chi2)`\n",
    "           \n",
    "<font size=\"3\">2Ô∏è‚É£ <span style=\"color:#0a51ab\">**M√©thodes bas√©es sur l'importance des variables** :</span>   </font>   \n",
    "   - **For√™t Al√©atoire** : S√©lectionne les variables ayant le plus d'impact sur les d√©cisions du mod√®le.\n",
    "        - üîπ Scikit-learn : `sklearn.ensemble.RandomForestClassifier().feature_importances_`\n",
    "    \n",
    "<font size=\"3\">3Ô∏è‚É£ <span style=\"color:#0a51ab\">**M√©thodes bas√©es sur la r√©gularisation** :</span>   </font>   \n",
    "   - **Lasso (L1 Regularization)** : Supprime automatiquement les variables peu importantes dans une **r√©gression lin√©aire/logistique**.    \n",
    "      - üîπ Scikit : `SelectFromModel(LogisticRegression(penalty='l1', solver='liblinear'), prefit=True)`\n",
    "\n",
    "\n",
    "Le plus souvent il faut tester **plusieurs approches** et √©valuer leurs performances via une **cross-validation** :   \n",
    "- **Les donn√©es r√©elles sont souvent complexes**, avec des relations lin√©aires et non lin√©aires.\n",
    "- **Le type d‚Äôalgorithme utilis√© influence la s√©lection des variables.**\n",
    "- **Le volume des donn√©es et leur qualit√© influencent la pertinence des m√©thodes.**\n",
    "\n",
    "üîπ **Objectif** : Trouver **le bon √©quilibre** entre **performance du mod√®le**, **r√©duction de la complexit√©** et **interpr√©tabilit√©** des r√©sultats. üöÄ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef78aff-3150-48bc-bb27-8f0faed42844",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
